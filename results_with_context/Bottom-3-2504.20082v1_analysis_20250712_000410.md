# Research Paper Analysis: Bottom-3-2504.20082v1.pdf

## Summary

| Metric | Value |
|--------|-------|
| **Paper** | Bottom-3-2504.20082v1.pdf |
| **Analysis Date** | 2025-07-12 00:04:10 |
| **Overall Score** | **7.60/10** |
| **Sections Analyzed** | 20 |
| **Processing Time** | 191.32 seconds |
| **Model Used** | claude-3-5-haiku-20241022 |

## Score Distribution

- **Abstract​**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Introduction**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Methods.**: 7.0/10 🟩🟩🟩🟩🟩🟩🟩⬜⬜⬜
- **Analysis Provides A Comprehensive Understanding Of How These Paradigms Can Effectively**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Background: Ai Agents And Agentic Workflows**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **Approach To**: 4.0/10 🟩🟩🟩🟩⬜⬜⬜⬜⬜⬜
- **Methodology**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **Evaluation Tools To Identify And Mitigate Harmful Language.**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Approaches Requiring Extensive Training Or Reinforcement Learning, Self-Refine Operates**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Methods. This System Models Diverse Student Personas, Providing Dynamic Interactions That**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Evaluation And Refinement, Making Them Resource-Intensive And Limiting Their Scalability In**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Approach In Rewoo Challenges The Agent To Adapt To A Dynamic Environment. Cognitive Load**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **Analysis, Which Are Crucial In**: 4.0/10 🟩🟩🟩🟩⬜⬜⬜⬜⬜⬜
- **Evaluation**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Limitations And Challenges. One Significant Issue Is The Seamless Integration Of Various**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Approach, Enabling Ai Agents To Enhance Engagement, Support Personalized Learning, And**: 8.0/10 🟩🟩🟩🟩🟩🟩🟩🟩⬜⬜
- **Limitations Such As**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **Conclusion**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **References**: 9.0/10 🟩🟩🟩🟩🟩🟩🟩🟩🟩⬜
- **Limitations, And Recommendations For Effective Integration. Interactive Learning**: 3.0/10 🟩🟩🟩⬜⬜⬜⬜⬜⬜⬜

---

## Detailed Section Analysis

### 1. Abstract​

**Score: 8.0/10**

**Evaluation:**
The abstract demonstrates strong qualities across all evaluation criteria: Clarity and Writing Quality (2/2): - Well-structured and concise - Clear progression of ideas - Professional academic language - Effectively communicates research scope and significance Technical Depth (2/2): - Articulates complex AI concepts precisely - Introduces specific agentic workflow paradigms - Highlights key technological limitations and opportunities Novelty and Originality (1.5/2): - Innovative focus on AI agents in educational contexts - Introduces unique multi-agent framework for essay scoring - Frames research within sustainability and technological advancement Methodology Rigor (1.5/2): - Outlines clear research approach - Mentions systematic examination of agentic workflows - Provides preliminary evidence through proof-of-concept application Evidence and Support (1/2): - Suggests preliminary results support claims - Acknowledges need for further research - Could benefit from more explicit evidence references

**Summary:**
This abstract explores the potential of AI agents in education by examining four key design paradigms: reflection, planning, tool use, and multi-agent collaboration. The research presents a multi-agent essay scoring framework as a proof-of-concept, highlighting the transformative potential of AI agents while acknowledging the need for further investigation into their interpretability and pedagogical impact.

<details>
<summary>📄 View Section Content (1412 characters)</summary>

```
Abstract​
Artificial intelligence (AI) has transformed various aspects of education, with large language 
models (LLMs) driving advancements in automated tutoring, assessment, and content 
generation. However, conventional LLMs are constrained by their reliance on static training 
data, limited adaptability, and lack of reasoning. To address these limitations and foster more 
sustainable technological practices, AI agents have emerged as a promising new avenue for 
educational innovation. In this review, we examine agentic workflows in education according to 
four major paradigms: reflection, planning, tool use, and multi-agent collaboration. We critically 
analyze the role of AI agents in education through these key design paradigms, exploring their 
advantages, applications, and challenges. To illustrate the practical potential of agentic systems, 
we present a proof-of-concept application: a multi-agent framework for automated essay 
scoring. Preliminary results suggest this agentic approach may offer improved consistency 
compared to stand-alone LLMs. Our findings highlight the transformative potential of AI agents 
in educational settings while underscoring the need for further research into their interpretability, 
trustworthiness, and sustainable impact on pedagogical impact. 
Keywords: AI Agents; Education; Artificial Intelligence; Automated Essay Scoring; LLM; GPT; 
Sustainability
```

</details>

---

### 2. Introduction

**Score: 8.0/10**

**Evaluation:**
The introduction demonstrates strong quality across the evaluation criteria: Clarity and Writing Quality (2/2): - Exceptionally clear, well-structured prose - Technical concepts explained accessibly - Smooth logical progression of ideas Technical Depth (2/2): - Provides sophisticated overview of AI agent evolution - Highlights key technological transitions - Differentiates between foundational models and advanced AI agents - Includes specific technical nuances like real-time information retrieval Novelty and Originality (1.5/2): - Presents emerging perspective on AI agents in education - Identifies limitations of previous models - Frames research within broader technological transformation context Methodology Rigor (1.5/2): - Acknowledges research limitations - Indicates need for further investigation - References contemporary research benchmarks Evidence and Support (1/2): - Includes multiple academic citations - References recent studies - Could benefit from more detailed empirical evidence

**Summary:**
The introduction explores the evolution of AI technologies in education, transitioning from foundational language models to more sophisticated, autonomous AI agents. It highlights the emerging potential of these agents while critically acknowledging the need for careful, strategic implementation in educational contexts. The section sets a comprehensive groundwork for examining AI's transformative role in learning environments.

<details>
<summary>📄 View Section Content (2162 characters)</summary>

```
1 Introduction 
Artificial intelligence (AI) has rapidly evolved in recent years, increasingly permeating various 
aspects of modern society, including education. The emergence of large language models 
(LLMs) has particularly expanded AI’s capabilities, creating opportunities to develop educational 
tools that not only enhance learning outcomes but also raise awareness of sustainable 
practices. Early applications in education largely relied on foundational models such as GPT or 
their fine-tuned variants (ChatGPT). While these models facilitated notable advancements in 
instruction and student support, they also operated under inherent constraints—limited 
adaptability, lack of nuanced reasoning, and reliance on static training data—that underscore 
the importance of ongoing research into sustainable, responsible AI innovations. 
A new generation of AI technologies seeks to overcome the limitations of the foundational 
models through the development of AI agents that function autonomously. AI agents utilize 
reflection, planning, and a wide range of tools to perform tasks with minimal human intervention. 
At the core of most AI agents lie sophisticated LLMs; however, their agentic layer distinguishes 
them from traditional systems by enabling more complex capabilities and autonomy. Specifically, 
agentic design leverages real-time information retrieval and dynamic task decomposition, 
reducing the reliance on dated or incomplete training data. As a result, AI agents are able to 
outperform stand-alone LLMs on numerous benchmark evaluations (Hong et al., 2024; Wu et 
al., 2024), demonstrating the considerable promise of agentic workflows in education (Guo et 
al., 2024).  
Although the implementation of AI agents within educational settings has begun to be 
investigated (Yusuf et al., 2025; Dai et al., 2024), their integration into educational settings 
requires careful examination and strategic implementation. Educational tasks require robust, 
trustworthy, and interpretable systems. Further research is needed to determine how AI-driven 
agents influence different learning environments, student populations, and pedagogical
```

</details>

---

### 3. Methods.

**Score: 7.0/10**

**Evaluation:**
The Methods section demonstrates good potential but requires some additional development. Strengths include: - Clear alignment with the abstract and introduction's framework of four AI agent paradigms - Initial indication of a structured approach to exploring each paradigm - Professional academic tone and use of scholarly citation Areas for improvement: - The section appears to be cut off mid-sentence, suggesting an incomplete draft - More specific details about the methodology of reviewing and analyzing these paradigms would strengthen the section - Need for more explicit explanation of how these paradigms will be systematically examined Scoring Breakdown: - Clarity: 2/2 - Clear and well-structured initial approach - Technical Depth: 1/2 - Promising framework, but lacks methodological specifics - Novelty: 1/2 - Builds on existing framework from introduction - Methodology Rigor: 1/2 - Outlines an approach but needs more methodological detail - Evidence and Support: 2/2 - Includes scholarly citation and clear conceptual structure

**Summary:**
This Methods section outlines a research approach focusing on four AI agent design paradigms in education: reflection, planning, tool use, and multi-agent collaboration. The section sets up a framework for comprehensive review, emphasizing the potential of these paradigms to enhance AI performance in educational contexts, while signaling an intent to critically examine their conceptual foundations and practical applications.

<details>
<summary>📄 View Section Content (573 characters)</summary>

```
methods. 
The primary goal of this paper is to provide a comprehensive review of existing AI agentic 
paradigms within the context of education. We focus on four major design paradigms: 1) 
reflection, 2) planning, 3) tool use, and 4) multi-agent collaboration. These paradigms are 
“crucial for boosting LLM productivity and enhancing performance” (Singh et al., 2024, p.1). We 
first describe each paradigm individually, discussing their conceptual foundations and respective 
advantages, practical applications, and associated challenges within educational contexts. Our
```

</details>

---

### 4. Analysis Provides A Comprehensive Understanding Of How These Paradigms Can Effectively

**Score: 8.0/10**

**Evaluation:**
- Clarity and Writing Quality (2/2): The section is well-written and provides a clear overview of the paper's structure and key contributions. The writing is concise and informative. - Technical Depth (2/2): The section demonstrates technical depth by introducing a proof-of-concept multi-agent system for essay scoring and outlining a structured approach to examining AI agent paradigms. - Novelty and Originality (1/2): While the approach seems promising, the novelty is slightly limited. The multi-agent essay scoring system is interesting, but the paradigm categorization feels somewhat incremental. - Methodology Rigor (1/2): The section hints at a structured methodology (literature review, systematic categorization) but doesn't provide extensive methodological details in this excerpt. - Evidence and Support (2/2): The section references a GitHub repository with the implementation and suggests empirical results showing improved consistency compared to standalone LLMs.

**Summary:**
The section provides a comprehensive overview of the research's approach to exploring AI agent paradigms in education, introducing a multi-agent essay scoring system as a proof-of-concept. It outlines the paper's structure, highlighting the systematic examination of AI agent design paradigms and their potential to overcome limitations of traditional language models.

<details>
<summary>📄 View Section Content (1427 characters)</summary>

```
analysis provides a comprehensive understanding of how these paradigms can effectively 
leverage AI agents to overcome the limitations of conventional large language models. 
To further illustrate the potential of an agentic approach in education, we present a 
proof-of-concept application: a multi-agent system designed for automated essay scoring 
(MASS). The results show that our proposed agentic framework achieves increased consistency 
and reliability in evaluating written work compared to stand-alone LLMs 
(https://github.com/AzizovDilshod/Multi-agent-System-for-Essay-Assessment/tree/main).  
The rest of the manuscript is organized as follows. In Section 2, we provide a conceptual 
overview of AI agents and agentic workflows. Crucially, we propose our categorization of agentic 
workflows in education in terms of four major paradigms (Figure 2.4). Section 3, describes the 
structured literature review methodology used  to analyze the role and potential of AI agentic 
workflows in education.  Our findings are synthesized narratively within Section 4, dedicating a 
subsection to each paradigm. Section 5 details our proposed multi-agent system for automated 
essay scoring, outlining its architecture, implementation, and empirical results. Finally, Section 6 
concludes with a discussion on the limitations of existing approaches and directions for future 
work in advancing agentic solutions for education.
```

</details>

---

### 5. Background: Ai Agents And Agentic Workflows

**Score: 9.0/10**

**Evaluation:**
The Background section is exceptionally well-crafted, demonstrating high-quality technical depth, clarity, and comprehensive coverage of AI agents and agentic workflows. Breakdown of scoring criteria: 1. Clarity and Writing Quality (2/2): The text is extremely clear, well-structured, and explains complex concepts in an accessible manner. 2. Technical Depth (2/2): Provides nuanced, detailed exploration of AI agent concepts, workflows, paradigms, and platforms with robust academic citations. 3. Novelty and Originality (1.5/2): Offers innovative framing of AI agents as an emerging "application layer" and comprehensively maps current agentic paradigms. 4. Methodology Rigor (2/2): Systematically breaks down agentic workflow phases, paradigms, and platforms with precise definitions and supporting evidence. 5. Evidence and Support (1.5/2): Strong use of recent citations, benchmark data, and illustrative figures to substantiate claims. The section seamlessly connects with previous sections, particularly the Methods section, by introducing the conceptual foundations of AI agents and previewing the four paradigms that will be explored in depth.

**Summary:**
This background section defines AI agents as dynamic, goal-oriented systems utilizing large language models, capable of autonomous interaction and task execution. It introduces four key agentic paradigms (reflection, planning, tool use, multi-agent collaboration) and explores emerging platforms for agent development, positioning these technologies as a transformative layer in the AI technology stack with significant potential across domains, including education.

<details>
<summary>📄 View Section Content (6106 characters)</summary>

```
2 Background: AI Agents and Agentic Workflows 
An AI agent can be defined as a system that utilizes an LLM as its core reasoning engine to 
determine the control flow of an application, interacting with its environment to achieve specific 
goals (Wang et al., 2023a; Xi et al., 2023). An agentic workflow refers to the structured process 
through which such autonomous or semi-autonomous agents operate. Unlike traditional LLMs, 
which are often constrained by the static knowledge embedded during training, AI agents are 
designed for dynamic interaction. They can actively retrieve real-time information, utilize various 
tools (e.g., calculators, databases, web search), and employ reasoning strategies to execute 
complex tasks (Fig. 2.1). This capacity for autonomous action with limited human intervention 
makes agentic workflows a powerful paradigm for building sophisticated LLM-based 
applications. 
 
 
Fig. 2.1 In the basic agentic workflow, the agent interacts with its environment based on its 
goals and abilities. 
The shift towards agentic systems is partly driven by the evolving landscape of AI development. 
While past progress in LLMs was fueled by scaling data and computation, limitations in data 
availability and computational resources are encouraging a focus on enhancing inference-time 
performance (Zeng et al., 2024). Techniques such as chain-of-thought prompting, 
self-consistency, ReAct (Reasoning and Acting), and reflection, which are often incorporated 
into agentic workflows, have been significant drivers of recent performance improvements (Wei 
et al., 2022; Yao et al., 2023; Shinn et al., 2023). 
Evidence suggests that agentic systems can outperform their stand-alone LLM counterparts 
across various domains. For example, benchmark results on tasks like HumanEval show 
significant performance gains when agentic frameworks are built upon base models like 
GPT-3.5 and GPT-4 (Fig. 2.2) (Ng, 2024). Similar improvements have been observed in coding 
benchmarks like TransCoder and MBPP (Zhong et al., 2024). In education, preliminary studies 
indicate that agentic systems can enhance tasks such as automated scoring (Lee et al., 2024; 
Guo et al., 2024), demonstrating the potential of these approaches within the educational 
domain. 
 
Fig. 2.2 Performance of GPT 3.5 and GPT-4 (zero-shot) on HumanEval along with agentic 
frameworks built on top of GPT (Ng, 2024). 
Conceptually, AI agents are forming a distinct "application" layer in the evolving AI technology 
stack (Fig. 2.3). While foundational models, cloud infrastructure, and hardware remain crucial, 
the agent layer focuses on orchestrating these components to execute complex, goal-oriented 
tasks, abstracting underlying complexity and enabling more seamless user interaction. 
 
Fig. 2.3 The new AI stack featuring the emerging layer of Applications. 
2.1 Agentic Workflow 
A general agentic workflow often involves several key phases, though specific implementations 
vary: 
1.​ Planning: The agent receives a goal, decomposes it into smaller, manageable 
sub-tasks, and sequences these tasks. 
2.​ Information Retrieval/Tool Use: The agent identifies information needs for each 
sub-task and utilizes available tools (e.g., web search, databases, APIs, other agents) to 
gather necessary data or perform specific actions. 
3.​ Task Execution & Refinement: The agent executes the planned tasks, monitors 
progress, potentially reflects on outcomes or feedback, and dynamically adjusts the plan 
or generates new tasks as needed until the overall goal is achieved. 
The degree of "agenticness" can vary widely, from a simple system using a single tool to 
complex multi-agent collaborations. As the technology matures, agents are expected to become 
increasingly autonomous and capable (e.g., OpenAI's advancements, DeepSeek-R1). 
Four major paradigms underpin many current agentic approaches (Ng, 2024; Singh et al., 
2024), as shown in Figure 2.4: 
1.​ Reflection: The agent analyzes its past actions or outputs to identify errors or areas for 
improvement and refine its future behavior. 
2.​ Planning: The agent explicitly creates and follows a sequence of steps or sub-goals to 
achieve a complex objective. 
3.​ Tool Use: The agent leverages external resources or functions (e.g., calculators, code 
execution, web search, APIs) to augment its capabilities. 
4.​ Multi-agent Collaboration: Multiple specialized agents work together, communicating 
and coordinating their actions to achieve a common goal. 
These paradigms, which form the basis of our review in Section 4, represent distinct but often 
complementary strategies for building effective AI agents. 
 
Fig. 2.4 Description of the four major agentic paradigms 
2.2 AI Agent Platforms 
Several platforms facilitate the development and implementation of agentic systems, such as 
AutoGen, CrewAI, LangGraph, MetaGPT, and Phidata (Table 2.1). These frameworks provide 
varying levels of structure, flexibility, and support for different agent architectures, enabling 
researchers and practitioners (including educators) to build custom agent-based applications. 
Table 2.1. Platforms for building and implementing agentic systems. 
Framework 
Key Features 
Pros 
Cons 
AutoGen (Wu et 
al., 2024) 
Open-source, flexible 
design, active community 
- Highly customizable 
- Integrates with 
various tools and 
human feedback 
- Steep learning 
curve - Potentially 
less structured than 
other frameworks 
MetaGPT 
(Hong et al., 
2024) 
Standardized prompt 
sequences, a rich library 
of predefined agents 
- Excels in 
orchestrating complex 
agent interactions - 
Reduces custom 
coding 
- Heavy reliance on 
asyncio - Less 
generalizable agent 
roles 
CrewAI 
(CrewAI, 2024) 
Production-oriented, 
structured role-based 
delegation 
- Clean, 
production-ready 
design - Facilitates 
predictable, reliable 
outcomes 
- Limits on agent 
re-delegation - 
Collects anonymized 
usage data, which 
may raise privacy 
concerns 
LangGraph 
(LangChain, 
2024) 
Graph-based multi-actor 
workflow, fine-grained 
state control 
- Clear, scalable
```

</details>

---

### 6. Approach To

**Score: 4.0/10**

**Evaluation:**
This section receives a low score due to several significant issues: 1. Clarity and Writing Quality (1/2 points): - The text appears to be a fragment or incomplete outline - Lacks coherent sentence structure - Minimal context or explanation provided 2. Technical Depth (1/2 points): - Extremely limited technical content - Cryptic bullet points without substantive explanation - No clear connection to the previously described AI agent paradigms 3. Novelty and Originality (0/2 points): - No novel insights presented - Lacks meaningful contribution to understanding multi-agent interactions 4. Methodology Rigor (1/2 points): - Vague reference to graph theory without elaboration - No methodological details or framework explained 5. Evidence and Support (1/2 points): - No citations or supporting evidence - Lacks substantive discussion of multi-agent interaction challenges

**Summary:**
The section appears to be an incomplete or draft-stage note about multi-agent interactions, briefly mentioning task specialization and graph theory without providing meaningful insights or context. The content lacks the depth and clarity expected in a research paper section.

<details>
<summary>📄 View Section Content (180 characters)</summary>

```
approach to 
multi-agent 
interactions - 
Encourages task 
specialization 
- Requires familiarity 
with graph theory- 
May be less suitable 
for broad, highly 
interconnected tasks
```

</details>

---

### 7. Methodology

**Score: 9.0/10**

**Evaluation:**
The Methodology section is exceptionally well-crafted, demonstrating high-quality research design and comprehensive approach: Clarity and Writing Quality (2/2): - Extremely clear, structured, and logically organized - Professional academic writing style - Explicit explanation of research methodology Technical Depth (2/2): - Detailed description of literature search strategy - Comprehensive selection criteria - Well-defined analysis framework - Systematic approach to synthesizing literature Novelty and Originality (1.5/2): - Innovative framework for analyzing AI agent paradigms - Structured approach to reviewing emerging technological landscape - Covers cutting-edge research in AI agents and education Methodology Rigor (2/2): - Transparent methodology with clear inclusion/exclusion criteria - Systematic literature review approach - Comprehensive database search strategy - Well-defined analysis framework Evidence and Support (1.5/2): - Extensive citations from recent literature - Multiple references to contemporary research - Includes both academic and technical sources

**Summary:**
The methodology section presents a structured literature review focusing on AI agentic workflows in education. It systematically outlines a comprehensive search strategy across academic databases, with explicit selection criteria targeting publications from 2020-2024. The research employs a framework analyzing four key AI agent paradigms: reflection, planning, tool use, and multi-agent collaboration, aiming to synthesize current research trends, applications, benefits, and challenges in educational contexts.

<details>
<summary>📄 View Section Content (9651 characters)</summary>

```
3 Methodology 
This paper employs a structured literature review methodology to analyze the role and potential 
of AI agentic workflows in education. The primary objective is to synthesize current research 
and identify key trends, applications, benefits, and challenges associated with four major 
agentic paradigms: reflection, planning, tool use, and multi-agent collaboration, as identified in 
recent surveys and framework discussions (e.g., Ng, 2024; Singh et al., 2024; Xi et al., 2023). 
3.1 Literature Search Strategy 
A systematic search was conducted across major academic databases, including Google 
Scholar, Scopus, Web of Science, and the ACM Digital Library. Search terms included 
combinations and variations of primary keywords such as "AI agents," "agentic workflows," 
"large language models," and "education," combined with paradigm-specific terms like 
"reflection," "planning," "tool use," "multi-agent systems," "autonomous agents," "agentic AI," 
and related concepts (e.g., "ReAct," "Reflexion," "chain-of-thought," "CRITIC," "SELF-REFINE"). 
Application-specific terms such as "automated tutoring," "personalized learning," "educational 
simulation," "automated scoring," and "adaptive learning" were also used to capture relevant 
educational contexts. 
3.2 Selection Criteria and Scope 
The review focused on publications primarily from 2020 to 2024, capturing the rapid 
advancements following the widespread adoption of powerful LLMs. Given the fast-paced 
nature of AI agent research, the selection included peer-reviewed journal articles and 
conference proceedings, alongside significant and highly cited arXiv preprints which constitute a 
substantial portion of the cited works (Madaan et al., 2023; Shinn et al., 2023; Mollick et al., 
2024; Guo et al., 2024). Key framework documentation and conceptual pieces from reputable 
sources (DeepLearning.ai, 2024; LangChain, n.d.; CrewAI, n.d.) were also included where they 
defined influential paradigms or architectures. 
In total, approximately 93 sources were identified and synthesized for the core of this review. 
Papers were included if they met the following criteria: 
●​ Discussed the concepts, mechanisms, or architectures of AI agents or agentic 
workflows. 
●​ Focused on one or more of the four target paradigms (reflection, planning, tool use, 
multi-agent collaboration). 
●​ Applied or discussed the potential application of these agentic paradigms within 
educational settings (higher education, K-12, professional training) or addressed tasks 
directly relevant to education (assessment, feedback, tutoring, simulation). 
●​ Addressed the advantages, challenges, or ethical considerations of using AI agents in 
education. 
Papers were excluded if they focused solely on foundational LLM capabilities without an agentic 
layer, dealt with AI applications in education unrelated to agentic workflows (e.g., traditional 
machine learning for prediction), were not available in English, or were primarily commercial 
advertisements lacking technical or conceptual depth. 
3.3 Analysis Framework 
The selected literature was analyzed using a framework structured around the four core 
paradigms. For each paradigm, the analysis focused on extracting and synthesizing information 
related to: 
1.​ Conceptual Foundations: Defining the paradigm's core principles, mechanisms, and 
key enabling techniques (e.g., citing works like Wei et al., 2022 for CoT; Yao et al., 2023 
for ReAct; Xu et al., 2023 for ReWOO; Gou et al., 2024 for CRITIC). 
2.​ Educational Applications: Identifying and categorizing reported or proposed uses in 
education, drawing on specific examples from the literature (e.g., Viswanathan et al., 
2022, Mollick et al., 2024 for multi-agent applications; Madaan et al., 2023 for reflection 
in feedback). 
3.​ Advantages: Summarizing the benefits highlighted in the literature compared to 
non-agentic approaches or traditional methods. 
4.​ Challenges and Future Directions: Consolidating reported limitations, implementation 
hurdles, ethical concerns (e.g., drawing on Bender et al., 2021; Chan, 2023; Kamalov et 
al., 2023), and suggested avenues for future research. 
3.4 Synthesis and Presentation 
The findings were synthesized narratively within Section 4, dedicating a subsection to each 
paradigm. Tables were used to summarize key studies (e.g., Table 4.1, 4.6, 4.9), architectures 
(Table 4.8), or concepts (Table 4.2, 4.3, 4.5, 4.7) for clarity. The illustrative case study presented 
in Section 5, while informed by the review (particularly the multi-agent paradigm), follows its own 
implementation and evaluation description (using the dataset from Crossley et al., 2024) and is 
distinct from the primary literature synthesis methodology. The overall aim is to provide a 
structured, evidence-based overview of the current state and future potential of AI agentic 
workflows in education, grounded in the identified body of literature. 
 
4 Agentic Paradigms in Education 
As outlined in Section 2, agentic workflows can be broadly categorized into four key paradigms: 
reflection, planning, tool use, and multi-agent collaboration. This section reviews each 
paradigm, discussing its foundations, specific roles and applications in education, and 
associated challenges. 
4.1 Reflection Systems 
AI-driven Reflection systems are designed to enable agents to evaluate their performance, 
identify areas for improvement, and iteratively refine their approaches to achieve tasks more 
effectively. By continually monitoring and adjusting strategies, these systems embody principles 
of sustainable growth—where perpetual learning and responsible resource use guide progress. 
This paradigm aligns closely with foundational principles from the science of learning, 
particularly those emphasizing the importance of metacognition and active engagement in 
learning processes (Kosslyn, 2017). In educational contexts, reflection systems offer 
transformative potential not only by fostering adaptive learning experiences and enhancing 
teaching methodologies and student outcomes but also by promoting awareness of sustainable 
practices. Through iterative feedback loops, such systems can encourage learners and 
educators alike to consider long-term impacts, optimize resource utilization, and integrate 
environmental stewardship into the learning process. 
These systems incorporate mechanisms that allow AI agents to assess their actions 
retrospectively, drawing lessons from successes and failures. Inspired by human cognition, 
these systems employ methods such as performance analysis, error detection, and strategic 
adaptation. Central to this is the concept of “deep processing,” wherein the deliberate 
examination of processes and outcomes enhances understanding and memory retention  
(Kosslyn, 2017). For AI agents, this means leveraging past experiences to refine their 
strategies, leading to improved task execution. 
 
Reflection systems in AI often use frameworks such as reinforcement learning and causal 
reasoning to model the effects of decisions and/or actions in achieving desired outcomes. 
Recent advancements in agentic design patterns emphasize the value of structured reflection to 
optimize task planning, execution, and adaptability (DeepLearning.ai, 2024). By implementing 
self-assessment loops, AI agents can iteratively improve their responses to complex challenges, 
demonstrating enhanced capabilities over time. 
 
4.1.1 Mechanisms of Reflection Systems 
Reflection systems are underpinned by several key mechanisms that define their functionality 
and potential. These mechanisms include interactive feedback loops, verbal reinforcement, and 
external verification and self-correction. Each mechanism provides a distinct but complementary 
pathway for enabling AI agents to reflect, learn, and adapt. These mechanisms build on both 
internal evaluation processes and external tools, creating a hybrid structure to address diverse 
challenges such as error detection, adaptability, and knowledge gaps. Together, they enable AI 
agents to iteratively analyze their outputs, refine their processes, and adjust their strategies with 
increasing autonomy and accuracy. 
4.1.1.1 Interactive Feedback 
Modern advancements in reflection systems focus on integrating external feedback 
mechanisms, such as the CRITIC framework (Gou et al., 2024). CRITIC represents a 
cutting-edge approach to reflection systems by empowering AI agents to self-correct through 
tool-interactive critiquing. This framework enables LLMs to validate and refine their outputs by 
engaging with external tools, including search engines, code interpreters, and calculators. By 
mimicking human behaviors of cross-referencing and interactive improvement, CRITIC 
enhances the ability of AI systems to identify and address errors in real-time.  
 
A key feature of CRITIC is its “verify-then-correct” cycle, where external tools are used to 
evaluate the accuracy, coherence, and reliability of the AI’s initial outputs. Based on critiques 
generated through these interactions, the AI refines its responses in iterative loops. This method 
mirrors the metacognitive processes of self-assessment and strategic adaptation found in 
human cognition. For example, in tasks such as free-form question answering, CRITIC 
leverages search engines to verify factual accuracy. In mathematical reasoning, it employs code 
interpreters to validate the logic and correctness of programmatic solutions. Additionally, CRITIC 
has demonstrated its effectiveness in reducing toxicity in content generation by utilizing external
```

</details>

---

### 8. Evaluation Tools To Identify And Mitigate Harmful Language.

**Score: 8.0/10**

**Evaluation:**
The section demonstrates strong technical depth and clarity in discussing evaluation tools for AI agents, particularly focusing on harmful language mitigation and self-improvement mechanisms. Strengths: - High technical rigor in explaining advanced AI reflection and self-correction techniques - Clear, structured presentation of three distinct approaches (CRITIC, Reflexion, SELF-REFINE) - Strong citations and references to contemporary research - Demonstrates novel approaches to AI agent self-improvement - Provides concrete examples of application domains Minor Weaknesses: - The section title doesn't fully match the content (more about reflection mechanisms than explicitly harmful language tools) - Abruptly cuts off mid-sentence at the end, suggesting incomplete draft - Could benefit from more explicit connection to educational context mentioned in previous methodology section Scoring Breakdown: - Clarity and Writing Quality: 2/2 (Very clear, technically precise language) - Technical Depth: 2/2 (Sophisticated explanation of AI reflection mechanisms) - Novelty and Originality: 1.5/2 (Presents cutting-edge approaches in AI self-improvement) - Methodology Rigor: 1.5/2 (Strong methodological descriptions of each approach) - Evidence and Support: 1/2 (Good citations, but could use more empirical evidence)

**Summary:**
The section explores advanced AI agent self-improvement techniques, focusing on three innovative frameworks: CRITIC (external validation), Reflexion (verbal reinforcement), and SELF-REFINE (iterative self-correction). These approaches demonstrate how AI systems can enhance their performance through sophisticated reflection and feedback mechanisms, enabling more adaptive and accurate computational processes across various domains.

<details>
<summary>📄 View Section Content (2728 characters)</summary>

```
evaluation tools to identify and mitigate harmful language. 
 
The integration of CRITIC into reflection systems marks a significant evolution in AI design by 
emphasizing the importance of external feedback as a complement to internal processing. 
Traditional reflection systems rely primarily on self-generated assessments, which can be 
limited by the model’s inherent knowledge gaps or biases. CRITIC addresses this limitation by 
incorporating external sources of truth, creating a hybrid system that combines the strengths of 
internal metacognitive processes with the objectivity of external validation. This hybrid approach 
has proven to yield substantial improvements in both accuracy and adaptability across a variety 
of tasks where precise and unbiased outputs are essential, such as generating financial models 
or scientific analyses. 
4.1.1.2 Verbal Reinforcement 
Frameworks like Reflexion (Shinn et al., 2023) utilize verbal reinforcement to guide agents in 
self-improvement. Reflexion agents process feedback as episodic memory, enabling them to 
iteratively adjust their actions and strategies, achieving state-of-the-art performance in diverse 
domains such as decision-making, reasoning, and programming (Shinn et al., 2023). Reflexion’s 
key innovation lies in its ability to transform binary or scalar feedback into detailed, actionable 
insights that are stored as long-term memory. This memory enables agents to recognize 
patterns of errors and adapt their approaches over multiple iterations, significantly enhancing 
performance across various tasks, including sequential decision-making and complex 
reasoning. 
 
Beyond theoretical advancements, Reflexion has shown particular promise in multi-step logical 
reasoning tasks, where verbal reinforcement allows agents to identify and address gaps in their 
reasoning chains. This mechanism is also critical in areas where adaptability is required, such 
as debugging software or conducting multi-stage workflows involving dependency tracking. 
4.1.1.3 External Verification and Self-Correction 
SELF-REFINE (Madaan et al., 2023) introduces an iterative feedback loop that allows LLMs to 
improve their outputs without external supervision. SELF-REFINE uses the same model to 
generate, critique, and refine outputs, iterating until a satisfactory result is achieved. This 
process is grounded in the principles of human self-reflection, where individuals improve their 
work through cycles of evaluation and revision. SELF-REFINE excels in tasks such as code 
optimization, dialogue generation, and sentiment reversal by ensuring that feedback is specific 
and actionable, directly addressing deficiencies in the initial outputs. Unlike traditional
```

</details>

---

### 9. Approaches Requiring Extensive Training Or Reinforcement Learning, Self-Refine Operates

**Score: 8.0/10**

**Evaluation:**
1. Clarity and Writing Quality (2/2): The section is exceptionally well-written, with clear, articulate language and a logical flow of ideas. The prose is sophisticated yet accessible, effectively explaining complex AI reflection mechanisms. 2. Technical Depth (2/2): The content demonstrates impressive technical depth, diving into nuanced aspects of reflection systems like SELF-REFINE, DeepSeek, and their applications in educational contexts. The explanation of iterative refinement and reasoning frameworks is comprehensive. 3. Novelty and Originality (1.5/2): The section presents novel insights into AI reflection systems, particularly in educational applications. The discussion of DeepSeek and its potential in learning environments shows creative thinking about AI's transformative potential. 4. Methodology Rigor (1.5/2): While not a traditional methodology section, the content provides a rigorous exploration of different reflection frameworks, their mechanisms, and empirical applications. The discussion of how these systems work is methodologically sound. 5. Evidence and Support (1/2): The section includes some citations and specific examples, but could benefit from more direct empirical evidence or quantitative performance metrics to substantiate claims about system effectiveness.

**Summary:**
The section explores advanced AI reflection systems like SELF-REFINE and DeepSeek, focusing on their ability to iteratively improve performance through self-correction and reasoning. It particularly emphasizes the transformative potential of these systems in educational contexts, demonstrating how they can enhance learning, assessment, and skill development through adaptive, personalized feedback mechanisms.

<details>
<summary>📄 View Section Content (7349 characters)</summary>

```
approaches requiring extensive training or reinforcement learning, SELF-REFINE operates 
within a single model and uses few-shot prompts to guide the refinement process. 
 
A unique aspect of SELF-REFINE is its ability to achieve significant performance gains with 
minimal computational resources. For instance, in code optimization tasks, SELF-REFINE not 
only improves efficiency but also enhances readability by iteratively refining algorithms based on 
self-provided feedback. Similarly, in dialogue generation, it transforms generic or incomplete 
responses into engaging and contextually appropriate conversations. This iterative capability is 
particularly effective in workflows where incremental improvement is vital, such as creating 
high-quality translations, polishing creative writing, or refining policy documents. 
 
A new innovative addition to reflection systems is the integration of advanced reasoning 
frameworks such as DeepSeek (DeepSeek-R1), an open-source AI model designed for 
complex problem-solving. DeepSeek employs reinforcement learning and cognitive reasoning 
strategies, enabling it to iteratively refine its output and perform tasks with heightened precision. 
These capabilities are especially relevant to reflection systems, where iterative feedback and 
self-correction are central to improving performance over time. 
 
DeepSeek ability to incorporate external feedback and prior knowledge aligns with the goals of 
reflection systems in education. For instance, its structured reasoning framework can enhance 
the functionality of educational tools by analyzing student responses, identifying logical 
inconsistencies, and refining explanations or feedback to better support learning objectives. This 
mirrors the iterative refinement seen in frameworks like CRITIC and SELF-REFINE  but 
expands on them by incorporating a broader range of reasoning and external validation 
mechanisms. 
 
By leveraging advanced reasoning, DeepSeek could strengthen reflection systems' capacity to 
adapt to diverse educational contexts. Its open-source nature also lowers barriers to 
implementation, providing a flexible platform for integrating reflection capabilities into intelligent 
tutoring systems, automated grading tools, or collaborative learning environments. DeepSeek 
exemplifies how cutting-edge AI models can deepen the scope of reflection systems by 
incorporating sophisticated reasoning, thereby promoting accuracy and adaptability in 
educational applications.  
 
The combination of CRITIC, Reflexion, SELF-REFINE, and DeepSeek showcases the evolution 
of reflection systems in AI. Together, these frameworks highlight the transformative potential of 
integrating internal and external feedback mechanisms, enabling AI agents to achieve higher 
levels of adaptability, accuracy, and reliability. These mechanisms collectively drive innovation 
across technical and creative domains, demonstrating the potential of reflection systems to 
redefine complex problem-solving and iterative improvement tasks. As reflection systems 
continue to advance, their applications in education are likely to expand, fostering more 
intelligent and human-like AI systems. 
4.1.2 Reflection Systems in Education 
In the field of education, reflection systems have emerged as transformative tools, offering new 
opportunities to enhance teaching, learning, and assessment. By leveraging iterative feedback, 
verbal reinforcement, and external verification & self-correction mechanisms, these systems 
enable AI-driven tools to provide dynamic, personalized, and effective educational experiences.  
Reflection systems are increasingly employed in intelligent tutoring systems (ITS), where they 
enable real-time adaptation to student needs. These systems monitor student interactions, 
detect areas of struggle, and refine instructional strategies accordingly. For example, an ITS 
powered by frameworks like SELF-REFINE analyzes student errors in mathematics and 
iteratively adjusts its explanations, tailoring them to the learner’s understanding. This approach 
not only deepens comprehension but also fosters metacognitive practices by prompting 
students to reflect on their problem-solving strategies (Rouzegar & Makrehchi, 2024; Madaan et 
al., 2023). 
Another promising application is in feedback generation and refinement. Reflection systems 
such as SELF-REFINE iteratively enhance feedback quality, making it more actionable and 
personalized. For example, in automated essay scoring, these systems provide detailed 
critiques on grammar, structure, and argumentation, enabling students to refine their writing 
over multiple revisions. By aligning with principles of deliberate practice, where iterative 
feedback drives skill acquisition, these systems contribute to long-term learning and 
improvement (Madaan et al., 2023). 
Reflection systems also play a vital role in collaborative learning environments, where they 
enhance group dynamics and ensure equitable participation. AI agents embedded in group 
projects analyze patterns of engagement, identify disparities in contributions, and recommend 
interventions to balance collaboration. For instance, tools based on Reflexion can monitor the 
flow of a group discussion, highlight under-participating members, and suggest prompts to 
ensure their active involvement (Shinn et al., 2023). These capabilities align with collaborative 
pedagogical practices, fostering accountability and collective success. 
In addition, reflection systems are instrumental in promoting metacognitive skills among 
learners. By tracking attention, engagement, and learning behaviors, these systems encourage 
students to reflect on their strategies and optimize their performance. For example, platforms 
integrating CRITIC can analyze a student’s engagement with learning materials and suggest 
adjustments to improve focus and retention. This reflective feedback helps learners develop 
self-regulation and deeper awareness of their learning processes (Cukurova, 2024; Gou et al., 
2024). 
In automated grading, reflection systems are utilized to ensure fairness and accuracy in 
assessments. By cross-referencing student responses with validated sources, these systems 
refine grading algorithms to minimize bias and errors. For instance, frameworks like CRITIC 
incorporate external tools such as search engines and knowledge graphs to validate grading 
decisions, ensuring consistency and objectivity. This iterative refinement process addresses 
common challenges in large-scale assessments, where uniformity and reliability are critical (Gou 
et al., 2024; Yesilyurt, 2023). 
Educational simulations also benefit from reflection systems, which enable students to practice 
real-world skills in immersive, AI-driven environments. In tools like PitchQuest, a multi-agent 
educational simulation, reflection mechanisms allow students to refine their performance 
through iterative feedback from AI-generated mentors and evaluators. These systems provide 
tailored guidance, fostering experiential learning and skill development in simulated settings 
(Mollick et al., 2024). 
Similarly, the EduAgent framework leverages generative AI to simulate student behaviors in 
educational environments, enabling both instructors and AI systems to refine their instructional
```

</details>

---

### 10. Methods. This System Models Diverse Student Personas, Providing Dynamic Interactions That

**Score: 8.0/10**

**Evaluation:**
The Methods section demonstrates strong technical depth and novelty in exploring AI-driven educational simulation and reflection systems. The evaluation criteria are met impressively: 1. Clarity and Writing Quality (2/2): - Well-structured prose - Clear articulation of complex AI methodological concepts - Coherent flow between paragraphs 2. Technical Depth (2/2): - Sophisticated explanation of reflection systems - Detailed description of DeepSeek's reasoning capabilities - Concrete examples of AI application in educational contexts 3. Novelty and Originality (1.5/2): - Innovative approach to modeling student personas - Advanced integration of reflection mechanisms - Unique perspective on AI-driven educational simulations 4. Methodology Rigor (1.5/2): - Systematic description of AI reasoning frameworks - Clear explanation of iterative adaptation processes - Supported by multiple research references 5. Evidence and Support (1/2): - Comprehensive citation of recent research - Inclusion of a detailed reference table - Some minor reduction due to limited empirical validation details

**Summary:**
The Methods section explores advanced AI reflection systems in educational contexts, focusing on DeepSeek's capabilities for modeling student personas and providing dynamic, adaptive learning interactions. By integrating sophisticated reasoning mechanisms, the research demonstrates how generative AI can create personalized, iterative learning environments that enhance educational experiences through real-time performance analysis and feedback.

<details>
<summary>📄 View Section Content (3964 characters)</summary>

```
methods. This system models diverse student personas, providing dynamic interactions that 
help educators test and optimize learning strategies. By incorporating reflection mechanisms, 
EduAgent can iteratively adapt its simulations based on real-time performance data, ensuring 
that interactions remain realistic and pedagogically effective. Such advancements highlight the 
role of generative AI in creating more adaptable and reflective learning simulations (XU et al., 
2024). 
DeepSeek further enriches the potential of reflection systems in education by introducing 
advanced reasoning capabilities tailored to complex educational settings. DeepSeek enables 
systems to analyze nuanced student behaviors, refine instructional strategies, and provide 
personalized feedback. For example, DeepSeek can identify logical inconsistencies in a 
student’s problem-solving approach and refine its explanations iteratively to enhance conceptual 
understanding. Its reinforcement learning framework supports dynamic adaptability, making it an 
invaluable tool for addressing individual differences in student learning styles and progress 
(Romero, 2024, DeepSeek, 2024).  
By integrating DeepSeek reasoning capabilities, reflection systems can advance the 
development of educational simulations and ITS platforms, where real-time evaluation and 
adjustment are critical. This includes applications in automated essay scoring, where the system 
assesses nuances such as argument coherence and writing style. Moreover, DeepSeek's ability 
to adaptively model complex behaviors enables it to simulate realistic student personas, 
enriching teacher training and curriculum testing environments.  
Reflection systems in education are a powerful means of personalizing instruction, fostering 
metacognition, and improving collaborative learning. As these systems continue to evolve, they 
will play a central role in creating adaptive, intelligent learning environments that align with the 
diverse needs of students and educators.  
 
Table 3.1. Reflection Systems in Education. 
Source 
Domain 
Summary 
Madaan et 
al. (2023) 
Feedback 
Refinement 
Introduce SELF-REFINE, a framework that iteratively 
enhances feedback quality for tasks such as essay scoring, 
dialogue generation, and code optimization. 
Shinn et al. 
(2023) 
Collaborative 
Learning 
Propose Reflexion, which uses verbal reinforcement to 
refine actions iteratively, improving group participation and 
active learning in educational projects. 
Cukurova 
et al. 
(2024) 
Metacognitive 
Practices 
Highlight how reflective systems track engagement and 
learning behaviors, encouraging students to optimize their 
learning strategies for better performance. 
Gou et al. 
(2024) 
Automated 
Grading 
Present CRITIC, a system that integrates external 
verification tools to enhance grading accuracy and fairness, 
particularly in large-scale assessments. 
Xu et al. 
(2024) 
Educational 
Simulations 
Propose EduAgent, a framework using generative AI to 
simulate realistic student behaviors, enabling teacher 
training and curriculum optimization. 
Mollick et 
al. (2024) 
Educational 
Simulations 
Propose PitchQuest, a simulation platform where reflection 
systems provide iterative feedback to refine learners' 
performance in experiential learning settings. 
DeepSeek  
(2024) 
Intelligent 
Tutoring 
Introduce DeepSeek, an open-source AI model using 
advanced reasoning and reinforcement learning to enhance 
ITS through interactive elements such as simulations, 
quizzes, and problem-solving exercises that engage 
students and enhance their understanding of complex 
concepts. 
 
4.1.3 Challenges and Future Directions 
Despite their distinct advantages, multi-agent systems also present several challenges. One 
major challenge is computational complexity, which arises from the iterative nature of reflection 
systems. Frameworks like CRITIC, SELF-REFINE, and DeepSeek rely on repeated cycles of
```

</details>

---

### 11. Evaluation And Refinement, Making Them Resource-Intensive And Limiting Their Scalability In

**Score: 8.0/10**

**Evaluation:**
The section demonstrates strong academic rigor and depth in addressing critical challenges and future directions for AI reflection systems in educational contexts. Strengths: 1. Clarity and Writing Quality (2/2): The text is well-written, coherent, and presents complex ideas in an accessible manner. Technical concepts are explained clearly. 2. Technical Depth (2/2): Provides comprehensive analysis of challenges in AI reflection systems, including computational efficiency, data privacy, bias propagation, and generalizability. 3. Novelty and Originality (1.5/2): Offers innovative perspectives on addressing AI system limitations, such as multimodal feedback integration and collaborative AI frameworks. 4. Methodology Rigor (1.5/2): Systematically explores potential solutions and future research directions, supported by credible academic citations. 5. Evidence and Support (1/2): Strong citation base, but some claims could benefit from more direct empirical evidence. Areas for Improvement: - More concrete examples of bias mitigation strategies - Deeper exploration of specific technical implementations - Slightly more quantitative analysis of proposed solutions

**Summary:**
The section critically examines challenges facing AI reflection systems in educational settings, highlighting issues of resource intensity, data privacy, and potential bias. It proposes forward-looking solutions like multimodal feedback, collaborative AI frameworks, and ethical alignment, emphasizing the importance of human-AI collaboration in educational technology. The evaluation considers the section's context within the broader research on AI-driven educational reflection systems, demonstrating a nuanced understanding of the field's current limitations and future potential.

<details>
<summary>📄 View Section Content (7914 characters)</summary>

```
evaluation and refinement, making them resource-intensive and limiting their scalability in 
resource-constrained educational settings (Gou et al., 2024; Madaan et al., 2023). Addressing 
this challenge will require innovations in computational efficiency and system optimization. 
Data privacy and security also remain critical concerns. Reflection systems analyze vast 
amounts of sensitive user data, including learning patterns and performance metrics, which 
must be safeguarded against misuse or unauthorized access. Adherence to regulations is 
essential to maintaining trust and ensuring the ethical use of AI in education (U.S. Department 
of Education, 2023). Thus, it is important to design systems that are both secure and 
transparent. 
Another issue is the propagation of biases in feedback. Self-generated or externally sourced 
feedback loops may inadvertently reinforce errors or perpetuate biases present in training data 
or external verification tools. For example, tools like search engines or code evaluators 
integrated into reflection systems may introduce inaccuracies if they themselves contain biases 
or errors (Shinn et al., 2023; Bender et al., 2021). To mitigate this, future systems will need 
mechanisms to identify and address such biases proactively. 
Reflection systems also face difficulties in generalizing across diverse educational contexts. 
While effective in specific domains, these systems often struggle to adapt to varied disciplines, 
cultural contexts, or instructional styles (Luckin et al., 2016). Ensuring flexibility and adaptability 
remains a critical area of research to enable broader deployment. Additionally, the lack of 
transparency in how reflection systems generate feedback raises ethical concerns. Students 
and educators need clear explanations of how these systems arrive at decisions to build trust 
and accountability in their use (Zhang et al., 2024a). 
Despite these challenges, the future of reflection systems in education is promising. Integrating 
multimodal feedback sources, such as speech, handwriting, and gestures, could greatly 
enhance the depth and quality of feedback (Cukurova, 2024; Kosslyn, 2017). For instance, 
systems could analyze a combination of verbal explanations and written solutions to provide 
comprehensive feedback tailored to individual learners. Collaborative frameworks, where 
multiple AI agents engage in reflective dialogues or interact with human educators, are another 
promising direction. Such systems could leverage the complementary strengths of AI and 
human expertise to deliver more robust and reliable feedback (DeepLearning.ai, 2024). 
Ethical alignment and pedagogical best practices will also play a pivotal role in shaping the 
future of reflection systems. Close collaboration between AI researchers and educators is 
essential to ensure that these systems are designed to be fair, inclusive, and supportive of 
diverse learning needs (Holmes et al., 2019). Moreover, balancing AI capabilities with human 
oversight will help prevent over-reliance on automated systems and ensure that critical thinking 
and metacognition remain integral to the learning process (U.S. Department of Education, 
2023). 
Finally, advancements in real-time adaptive feedback offer significant potential for education. 
For instance, during group activities, reflection systems could monitor team dynamics in 
real-time and provide actionable recommendations to improve collaboration (Mollick et al., 2024; 
Zhang et al., 2024b). These innovations, coupled with efforts to ensure transparency and 
address bias, will help reflection systems become more effective and equitable tools for 
education. 
4.2 Planning Systems 
To fully harness the power of LLMs in education, it is crucial to explore and implement agentic 
design patterns that enable AI agents to autonomously select options, plan, process, revise, 
solve, and execute complex tasks. By decomposing these complex tasks into smaller, more 
manageable subtasks—often involving interaction with external tools and resources (Chase, 
2024; Hu & Clune, 2024; Hu et al., 2024)—educational systems can become both more efficient 
and more sustainable. This modular approach not only facilitates targeted interventions and 
personalized support for learners but also helps optimize resource use, thereby reducing 
computational overhead and contributing to long-term ecological viability. 
 
Abuelsaad et al. (2024) and Wei et al. (2022) showed for instance, that chain-of-thought (CoT) 
prompting significantly improved LLMs' multistep reasoning abilities and “explanations” (Turpin 
et al., 2024), breaking tasks “step by step” (Yao et al., 2024) and problems “into intermediate 
reasoning steps, guiding the model through logical processes to reach a final conclusion” 
(Zhang et al., 2024a, p. 6817), according to two approaches (Singh et al., 2024; Xu et al., 2023): 
a) decomposition and b) interleaved approach. 
 
In decomposition, the LLM fully decomposes the primary task first into a set of constituent 
sub-tasks. Subsequently, the LLM generates independent sub-plans for each of these 
sub-tasks, outlining the specific actions required for their fulfillment before execution starts. 
Finally, these sub-tasks are executed sequentially, ensuring the completion of each sub-task in 
a predetermined order until the overarching task is achieved (Singh, 2024; Xu et al., 2023). 
 
In the interleaved approach, decomposition, planning, and execution are intricately intertwined. 
Rather than conducting a complete initial decomposition of the overarching task, the LLM Agent 
commences with a partial decomposition, typically focusing on an initial sub-task. Concurrently, 
planning and execution pertaining to this sub-task are initiated. As each sub-task is addressed, 
the agent dynamically adapts by identifying and incorporating newly recognized sub-tasks into 
the planning and execution process. The iterative cycle of decomposition, planning, and 
execution fosters a degree of flexibility, enabling the agent to effectively respond to unforeseen 
environmental complexities or emergent changes (Singh, 2024; Xu et al., 2023). The two 
prominent approaches to enhance the planning process are usually referred to as ReACT and 
ReWOO in the literature (Xu et al., 2023). 
 
ReACT is a framework that emphasizes the iterative interplay between reasoning and acting. It 
involves the following steps:(1) Reasoning: The agent analyzes the current situation, identifies 
potential actions, and predicts their outcomes; (2) Acting: The agent executes the chosen 
action, interacting with the environment; (3) Observing: The agent perceives the consequences 
of its action, updating its understanding of the world; and (4) Reflecting: The agent evaluates the 
outcome, adjusts its plan if necessary, and repeats the cycle. 
 
In ReWOO, the agent can leverage a broader range of knowledge and context to inform its 
decision-making. The key steps in ReWOO are:(1) The planner generates a comprehensive 
plan, considering various possibilities and constraints; (2) The generated plan instructs the 
worker to interact with the environment, use tools, and collect evidence. The worker 
adapts/adjusts the plan in real-time based on new information or changing circumstances; and 
(3) The solver receives the full plan and generates the final response. There is a strong 
connection between the interleaved approach in ReWOO and the concept of interleaving in 
cognitive load theory. Both approaches emphasize the benefits of mixing things up. In cognitive 
load theory, it is about mixing practice; in ReWOO, it is about mixing planning, execution, and 
decomposition. 
 
Both aim to enhance performance by challenging the student/agent. Interleaving in cognitive 
load theory challenges students to discriminate between concepts, while the interleaved
```

</details>

---

### 12. Approach In Rewoo Challenges The Agent To Adapt To A Dynamic Environment. Cognitive Load

**Score: 9.0/10**

**Evaluation:**
The section demonstrates exceptional quality across all evaluation criteria: 1. Clarity and Writing Quality (2/2): - Extremely well-structured and articulate - Clear progression of ideas with logical flow - Sophisticated academic writing style 2. Technical Depth (2/2): - Comprehensive exploration of AI planning systems - Detailed breakdown of planning processes - Nuanced discussion of tool-use mechanisms - Multiple theoretical and practical examples 3. Novelty and Originality (2/2): - Innovative framework for understanding AI agent planning - Unique categorization of planning systems - Forward-looking applications in educational contexts - Addresses emerging challenges in AI implementation 4. Methodology Rigor (1.5/2): - Systematic approach to analyzing AI planning - Robust methodological framework - Comprehensive table-based classifications - Slight deduction for potential over-complexity 5. Evidence and Support (1.5/2): - Extensive citations from recent research - Multiple empirical examples - Balanced discussion of potential challenges - Minor deduction for some speculative projections

**Summary:**
The section provides a comprehensive exploration of AI planning systems, focusing on their potential applications in educational contexts. It systematically categorizes planning approaches, discusses tool-use mechanisms, and presents a nuanced framework for understanding how AI agents can adaptively solve complex problems. The research emphasizes both the transformative potential and ethical considerations of AI planning in education.

<details>
<summary>📄 View Section Content (24077 characters)</summary>

```
approach in ReWOO challenges the agent to adapt to a dynamic environment. Cognitive load 
theory focuses on how the human brain processes information (Hultberg et al., 2018), while the 
interleaved approach in ReWOO focuses on the agent's decision-making process and its 
interaction with the environment. 
In essence, both interleaving approaches share the underlying principle of breaking down rigid 
structures and introducing flexibility to improve performance. In cognitive load theory, this 
flexibility enhances learning and memory, while in ReWOO, it enhances an agent's ability to 
navigate and adapt to complex situations. 
 
Planning systems are, therefore, a critical component of AI agents, enabling them to (1) Define 
clear objectives/goals/outcomes for the agent's actions; (2) Generate Plans and create a 
sequence of actions to achieve the goals; and (3) Execute the planned actions, “accomplish a 
task end-to-end” (Masterman et al., 2024, p.1), monitoring progress and adapting as needed. 
 
In terms of planning, agentic planning systems can be categorized into the following five 
categories, as shown in Table 4.2. 
 
Table 4.2.  Agentic Planning Systems  
 
Reactive Planners Reactive Planners lack explicit planning capabilities. They operate 
based on simple stimulus-response rules or pre-defined behaviors. 
They react to immediate changes in their environment without 
considering long-term goals or consequences. 
Simple Planners 
Simple Planners can perform basic planning by breaking down simple 
tasks into a sequence of actions. They may use simple search 
algorithms or rule-based systems to generate plans. However, they lack 
the ability to handle complex or dynamic environments. 
Goal-Oriented 
Planners 
Goal-Oriented Planners can define and pursue specific goals. They can 
generate and execute plans to achieve these goals, considering 
constraints and available resources. They may also be able to adapt 
their plans based on feedback or unexpected events. 
Learning Planners Learning Planners can learn from past experiences and improve their 
planning capabilities over time. They can adapt their planning strategies 
based on successes and failures, leading to more efficient and effective 
plans. (e.g. WebAgent, Gur et al., 2023) 
Self-Improving 
Planners 
Self-Improving Planners can not only learn from past experiences but 
also actively seek out new information and knowledge to improve their 
planning capabilities. They can continuously refine their planning 
algorithms and strategies, leading to increasingly sophisticated and 
autonomous behavior. 
 
The planning process is shown in Figure 4.1 and described step by step below: 
 
Fig. 4.1 The sequence of the agentic planning process  
 
1. Input and Goal Definition: 
●​ The agent clearly defines its desired outcome or objective. 
●​ This goal provides direction for the planning process. 
2. Data Analysis & Understanding: 
●​ The input data is processed using machine learning to identify patterns and gather 
insights. 
3. Action Modeling: 
●​ The agent identifies potential actions that can be taken to move toward the goal 
4. Plan Generation: 
●​ The agent uses a planning algorithm (e.g., search algorithms like depth-first search, 
breadth-first search, or A* - heuristic search) to explore possible sequences of actions, 
considering constraints and possible outcomes. 
5. Refinement & Simulation: 
●​ The agent may refine the plan based on feedback or new information, simulating 
outcomes to ensure efficiency and effectiveness. 
6. Execution & Monitoring: 
●​ The agent executes the chosen plan, carries out the sequence of actions, and monitors 
its performance.  
7. Learning & Feedback: 
●​ The agent learns from the outcomes and feedback (loop), improving its planning 
capabilities for future tasks. 
 
The planning process, which involves the formulation of a sequence of actions to achieve 
specific goals, holds significant potential for transforming educational practices and outcomes. 
By leveraging the structured, adaptive, and goal-oriented nature of AI planning, educators can 
create personalized learning experiences, design curricula, optimize resource allocation, and 
enhance decision-making processes in educational settings. AI planning systems, which are 
designed to solve complex problems by breaking them down into manageable steps, can be 
applied to curriculum design, individualized learning pathways, and administrative tasks, thereby 
addressing some of the most pressing challenges in education today. 
One of the most promising applications of AI planning in education is the development of 
personalized learning experiences (Kaswan et al., 2024; Sajja et al., 2024). Current educational 
models often adopt a one-size-fits-all approach, which fails to account for the unique learning 
preferences and paces of individual students. AI planning agents can address this limitation by 
analyzing vast amounts of data on student performance, engagement (in class or online), and 
behavior to create customized learning plans. For instance, an AI system can assess a 
student’s strengths and weaknesses in a particular subject, identify gaps in knowledge, and 
generate a tailored sequence of learning activities to address those gaps (Kikalishvili, 2024). 
This adaptive learning process ensures that students receive targeted support and challenges, 
thereby maximizing their learning potential (Kabudi et al., 2021). Moreover, AI planning can 
dynamically adjust these learning pathways in real-time based on ongoing assessments, 
ensuring the educational experience remains relevant and effective as students progress 
(Hyper-personalization). Research by Copyleaks (2024) indicated that 87% of educators and 
78% of students believed that AI could revolutionize education through personalized learning 
experiences. 
AI planning agents can further enhance personalization by generating detailed, constantly 
updated journey maps and reports for individual students or cohorts. These journey maps 
analyze and visualize the digital and physical multi-touchpoint experiences of students from 
enrollment to graduation, using techniques such as knowledge tracing (Shehata et al., 2023) 
and predictive modeling based on academic results, GPA, interests, selected study programs, 
study plans, and academic advisors’ reports. Such comprehensive views of student journeys 
enable institutions to identify critical interaction points, align academic programs and support 
services with evolving student needs, facilitate collaboration across institutional departments, 
and support data-driven decision-making for recruitment, engagement, retention, and alumni 
relations. 
In addition to personalization, AI planning can significantly enhance curriculum design by 
optimizing the sequencing and delivery of educational content. Curriculum development 
requires careful consideration of learning outcomes, prerequisite knowledge, constructive 
alignment, and logical progression. AI systems can analyze these factors and design coherent, 
efficient curricula. For instance, an AI planning agent can determine the optimal sequence for 
teaching topics, ensuring that students build foundational knowledge before tackling advanced 
material. This structured approach not only improves learning outcomes but also reduces 
cognitive load. Moreover, AI agents can continuously adapt curricula by automatically updating 
program maps when new courses are added, considering student-specific prerequisites and 
interests. They can also suggest electives from other programs aligned with career goals or 
research interests and align assessment tasks closely with specific learning outcomes, enabling 
comprehensive evaluation and performance predictions. 
AI planning capabilities extend further into educational decision-making, providing insights and 
recommendations to support evidence-based practices. Educational decision-making often 
involves complex trade-offs and uncertainties, such as determining effective teaching strategies 
or assessing policy impacts. AI systems can analyze historical and real-time data to generate 
predictive models and scenario analyses (Hao et al., 2024). For example, an AI agent can 
simulate potential outcomes of various interventions or teaching methodologies, thereby 
recommending the most effective actions. Personalized recommendation systems that 
continuously learn from user interactions can help plan comprehensive teaching and learning 
activities that align with learning outcomes, student engagement, and assessment strategies 
(Yusuf et al., 2025). 
Moreover, AI planning can foster collaborative learning environments, essential for developing 
critical thinking, communication, and teamwork skills. AI agents facilitate collaboration by 
organizing group activities, assigning roles based on individual student abilities, and monitoring 
progress. Systems like Bland AI provide real-time feedback and multilingual guidance, helping 
groups overcome challenges and remain goal-focused. 
AI planning is also instrumental in optimizing resource allocation within educational institutions, 
addressing challenges related to limited resources like time, funding, and personnel. For 
instance, AI agents can analyze student enrollment data, faculty availability, and classroom 
capacity to create optimal timetables, allocate budgets effectively, prioritize projects, and 
streamline administrative processes. By automating these tasks, educators and administrators 
can concentrate on strategic initiatives and direct student engagement. Additionally, planning 
agents can select and organize educational resources tailored to individual student profiles, 
adjusting difficulty levels in real-time and visualizing information through mind maps. Such visual 
representations help students connect new information to their existing knowledge, thereby 
reducing cognitive load and enhancing learning (Hultberg & Calonge, 2017). 
Finally, the integration of AI planning into education also has the potential to address issues of 
equity and access (Kamalov et al., 2023), which remain significant barriers to achieving 
universal quality education. AI systems can analyze data on student demographics, 
socioeconomic status, and geographic location to identify disparities in educational opportunities 
and outcomes. Based on this analysis, AI planning agents can design targeted interventions to 
support underserved populations, such as providing additional resources to schools in 
low-income areas or offering personalized tutoring to students who are at risk of falling behind. 
Furthermore, AI planning can facilitate the delivery of education in remote or 
resource-constrained settings (Kouam & Muchowe, 2025) through the use of digital platforms 
and adaptive technologies (Shah & Calonge, 2023). By leveraging AI to bridge gaps in access 
and quality (Aderibigbe et al., 2023), educators can work toward creating a more inclusive and 
equitable educational system. 
 
Despite its numerous advantages, the implementation of AI planning in education is not without 
challenges. One of the primary concerns is the ethical use of data, as AI systems rely on vast 
amounts of personal information to function effectively. Ensuring the privacy and security of 
student data is paramount, and institutions must establish robust policies and safeguards to 
protect sensitive information. Additionally, there is a risk of algorithmic bias (Chan, 2023), where 
AI systems may inadvertently perpetuate existing inequalities or reinforce stereotypes. To 
mitigate/minimize this risk, it is essential to develop AI planning models that are transparent, 
accountable (Habbal et al., 2024), and regularly audited for fairness. 
 
In conclusion, the planning process in AI agents offers a powerful framework for addressing 
some of the most pressing challenges in education, from personalizing learning experiences to 
optimizing resource allocation and enhancing decision-making. By leveraging the structured, 
adaptive, and goal-oriented nature of AI planning, educators can create more effective, efficient, 
and equitable educational systems. However, realizing the full potential of AI planning in 
education requires careful consideration of ethical, technical, and practical issues, as well as a 
commitment to fostering collaboration and innovation among all stakeholders. 
4.3 Tool-use systems 
In the domain of AI agents, the concept of "tools-use" refers to any functions or capabilities that 
the model can utilize to enhance its performance (Dwivedi et al., 2021). These tools enable 
agents to interact with external data sources, thereby facilitating the flow of information by 
retrieving or sending data and information to these sources. For instance, an AI agent designed 
as an educational tutor for high school mathematics. This persona is equipped with a deep 
understanding of mathematical concepts and the specific tasks it must accomplish, along with a 
suite of tools that facilitate various functions. These tools may include a graphing calculator for 
visualizing complex equations, a database of educational resources for providing supplementary 
materials, and a communication interface for sending personalized feedback to students via 
email or a messaging platform. The agent can analyze a student’s performance on practice 
problems, identify areas of difficulty, and then use its tools to generate tailored practice 
exercises or recommend videos and articles that explain challenging concepts.  
 
A notable benefit of adopting an agent-based approach, as opposed to relying solely on 
prompting-based language models, lies in the agents' ability to address complex problems 
through the coordinated application of multiple tools (Shinn et al., 2023). Such tools empower 
agents to engage with external data sources, interact with existing APIs, and execute a variety 
of functions that significantly enhance their problem-solving capabilities. Tasks that necessitate 
extensive tool utilization are often intertwined with those that require intricate reasoning. Both 
single-agent and multi-agent architectures can effectively tackle challenging tasks by integrating 
reasoning and tool-calling mechanisms. 
 
Many methodologies involve iterative processes of reasoning, memory utilization, and reflection 
to navigate and resolve problems with efficacy (Shinn et al., 2023; Shin et al., 2024). This often 
involves decomposing larger issues into smaller, more manageable subproblems that can be 
addressed sequentially using the appropriate tools, as explained above. Prior research (i.e., 
Dwivedi et al., 2021; Yao et al., 2023; Gao, 2024) indicates that while breaking down complex 
problems into smaller components can facilitate effective solutions, single-agent patterns 
frequently encounter challenges when faced with the lengthy sequences of actions required to 
complete these tasks. 
 
4.3.1.Components and Mechanisms of Tool-Use Systems 
The tool-use components and mechanisms in AI agents are fundamental for enabling dynamic 
interactions with external data sources and functionalities. This mechanism allows agents to 
execute complex tasks by leveraging various tools, thereby enhancing their capabilities to 
provide accurate and contextually relevant outputs. The following table summarizes the basic 
components and Processes of Tool-use in AI agents. 
Table 4.3. Components and Mechanisms of Tool-Use Systems. 
 
Components 
Processes described 
Prompting and Tool Invocation 
The agent initiates tool use through specially formatted 
requests. 
Upon recognizing strings, a post-processing 
component triggers the appropriate tool, executes the 
function, and returns the results for further processing. 
Iterative Reasoning 
The tool use mechanism often involves iterative 
reasoning, where the agent reflects on previous 
outputs and adjusts its approach based on the 
information retrieved from external sources. 
Content Management 
Context management is crucial when multiple tools are 
available. The agent must determine the most relevant 
tools for the current task, often employing heuristics to 
prioritize tool selection. 
Multi-Agent Collaboration-ready tool 
In complex scenarios, multiple agents may collaborate, 
each employing specialized tools to address 
subproblems. This enhances efficiency and allows for 
parallel processing of tasks. 
 
 
The tool use mechanism in AI agents encompasses several key components and processes 
that enhance their functionality (see Table 4.3). Prompting and Tool Invocation begins the 
process, where the agent initiates tool use through specially formatted requests. Upon 
recognizing these strings, a post-processing component activates the appropriate tool, 
executing the designated function and returning results for further analysis. This leads to 
Iterative Reasoning, where the agent reflects on previous outputs, adjusting its approach based 
on new insights gained from external sources. Effective Content Management is essential as 
well, especially when multiple tools are available; the agent must discern the most relevant tools 
for the current task, often utilizing heuristics to prioritize tool selection. Finally, in more complex 
scenarios, multi-agent collaboration comes into play, allowing multiple agents to work together, 
each leveraging specialized tools to tackle subproblems. This collaborative approach not only 
enhances efficiency but also facilitates parallel processing of tasks, resulting in a more robust 
and adaptive system. 
Indeed, “tools” are specific functions or capabilities that the AI agent can invoke. Each tool 
corresponds to a goal followed by an action, such as retrieving data, performing calculations, or 
interacting with third-party applications. 
Table 4.4.  Tool-use System (Operational Framework) Example 
Steps 
Description of Goals and 
Actions 
Examples of Tools and Models 
used 
1. Tool Initiation 
The session begins with the 
agent receiving a task or 
query that necessitates tool 
use 
For example, user input prompts - 
“Who is the program leader XXX of 
University of XXX, analyses his/ her 
publications and send an “Happy New 
Year” email to him/her and wish the 
person good luck in his/her career”. 
- “Visualize the class composition with 
simple statistics and figures” 
2. Tool Selection 
The agent evaluates available 
tools based on the task's 
context and formulates a plan 
for invoking the necessary 
functions 
·  Web-search (e.g. Google Search 
API for retrieving current 
information) 
·  SMTP Email Sender for sending 
automated emails 
·  OpenCV Library for performing 
image recognition 
·  SQL Database Connector to 
retrieve user-specific information. 
3. Execution of Tool 
Functions 
The agent constructs tool 
invocation strings and 
executes the associated 
functions 
·  Sending requests to APIs (e.g., 
Twitter API for social media 
interactions). 
·  Code execution tool: executing 
Python code 
4. Data Processing 
and Reflection 
Once the tools return results, 
the agent processes the 
incoming data, incorporating 
it into its understanding of the 
task. The agent may then 
reflect on this information, 
iterating its reasoning to 
refine its output. 
·  Pandas: A library for data 
manipulation and analysis in 
Python. An AI agent can use 
Pandas to clean, transform, and 
analyze datasets. 
·  NumPy: A library for numerical 
computing in Python. An agent 
can utilize NumPy for performing 
mathematical operations on large 
arrays and matrices. 
·  Apache Spark: A unified analytics 
engine for large-scale data 
processing. An AI agent can use 
Spark to handle big data 
processing tasks efficiently. 
5. Output 
Generation 
The agent synthesizes the 
information gathered through 
tool use and generates a 
coherent response or action. 
This output is informed by 
both the initial task and the 
insights gained from the tools 
·  Matplotlib for visualizing data 
·  TensorFlow: An AI agent can use 
TensorFlow to retrain models 
based on new data or feedback, 
reflecting on previous 
performance. 
·  Scikit-learn: An agent can 
evaluate model performance and 
adjust parameters based on 
reflection from past predictions. 
·  Jupyter Notebooks: An interactive 
computing environment where 
agents can document their 
processing steps, visualize data, 
and reflect on the outcomes of 
their analyses. 
 
The operational framework of AI agents (see Table 4.4) involves a series of structured steps 
designed to effectively address user tasks through tool utilization. Tool Initiation marks the 
beginning of this process, as the agent receives a task or query that necessitates tool use. For 
example, a user might prompt the agent with, “Who is the program leader of XXX in the 
University of YYY, analyze his/her publications, and send a Happy New Year email to her, 
wishing him/her good luck in her career,” or “Visualize the class composition with simple 
statistics and figures.” Following this, in the Tool Selection phase, the agent evaluates the 
context of the task and formulates a plan for invoking the necessary functions, considering tools 
such as the Google Search API for retrieving current information, SMTP Email Sender for 
sending automated emails, OpenCV Library for performing image recognition, and SQL 
Database Connector for accessing user-specific data. In the Execution of Tool Functions step, 
the agent constructs tool invocation strings and executes the associated functions, which may 
include sending requests to APIs like the Twitter API for social media interactions or executing 
Python code for data analysis. After the tools return results, the agent enters the Data 
Processing and Reflection phase, where it processes the incoming data to deepen its 
understanding of the task. This can involve using libraries like Pandas for data manipulation 
(Wang et al., 2024), NumPy for numerical computations, or Apache Spark for large-scale data 
processing. Finally, in the Output Generation step, the agent synthesizes the information 
gathered through tool use and generates a coherent response or action, informed by both the 
initial task and insights gained. This output may leverage tools like Matplotlib for data 
visualization (Wang et al., 2024), TensorFlow for model retraining based on new data, 
Scikit-learn for evaluating model performance, and Jupyter Notebooks for documenting 
processing steps and reflecting on outcomes. Through these steps, AI agents effectively 
navigate complex tasks, utilizing a variety of tools and models to deliver accurate and 
contextually relevant results. 
4.3.2. Type of Tool-Use Systems 
Aforementioned, within the tool-use systems paradigm, tools are essential for enhancing the 
capabilities of AI agents, allowing them to perform complex tasks effectively. These tools can be 
categorized into several groups based on their functionalities and applications. In Table 4.5 
below, we outline key types of tool-use systems, providing descriptions and examples for each 
type. 
Table 4.5.  Type of Tool-use System 
 
Type of Tools 
Descriptions 
Examples 
Data and 
Information 
Processing 
Tools 
Data Processing 
and Analysis 
Focuses on the collection, 
manipulation, and analysis of 
data to extract meaningful 
insights. They enable AI 
agents to handle large 
datasets and perform 
data-driven decision-making. 
Pandas: data 
manipulation, Apache 
Spark : large-scale 
data processing, 
Google search engine 
APIs for web enquiries 
Natural Language 
Processing (NLP) 
Empowers AI agents to 
understand, interpret, and 
generate human language, 
facilitating communication 
between the agent and users. 
They enhance the ability to 
process textual information 
effectively 
SpaCy: text 
processing, NLTK: 
linguistic data analysis 
Computer Vision 
Enables AI agents to interpret 
and analyze visual 
information from the world, 
allowing for tasks such as 
image recognition and video
```

</details>

---

### 13. Analysis, Which Are Crucial In

**Score: 4.0/10**

**Evaluation:**
The section appears fragmented and incomplete, with several critical issues: 1. Clarity and Writing Quality (1/2 points): - The text is extremely disjointed and lacks coherent narrative structure - Formatting seems inconsistent and appears to be a partial or truncated section - Grammatical and syntactical issues make comprehension difficult 2. Technical Depth (1/2 points): - While the section attempts to outline tools and their functions, the content is superficial - Limited technical explanation of how these tools interact or their specific mechanisms - Lacks depth in describing the actual implementation or significance of these tools 3. Novelty and Originality (1/2 points): - No clear original contribution is evident - Lists of tools are presented without innovative framing or unique insights - Appears more like a preliminary draft than a refined research section 4. Methodology Rigor (0/2 points): - No clear methodological approach is presented - No explanation of how these tools are selected or evaluated - Lacks systematic framework for understanding the tool ecosystem 5. Evidence and Support (1/2 points): - Minimal contextual support for tool selections - No citations or empirical evidence backing the tool descriptions - Appears more like a rough categorization than a rigorous analysis

**Summary:**
The section seems to be an incomplete draft attempting to categorize AI tools across different domains like image processing, decision-making, and interaction. It provides basic tool names and brief functional descriptions without substantive analysis or deeper insights into their educational or technological significance. Recommendations: - Complete the section with full paragraphs - Provide clear contextual framing - Add depth to tool descriptions - Include research-backed rationales for tool selection - Ensure coherent narrative flow

<details>
<summary>📄 View Section Content (1133 characters)</summary>

```
analysis, which are crucial in 
simulations and interactive 
environments. 
OpenCV: image 
processing, 
TensorFlow: deep 
learning applications 
in vision 
Yolo: object detection 
algorithm 
 
Planning, 
Modeling and 
Decision 
Making Tools 
Decision Making 
and Planning 
Tools 
Assists AI agents in making 
informed decisions and 
planning complex tasks by 
analyzing various factors and 
potential outcomes. 
IBM Decision 
Optimization for 
planning and 
scheduling, Microsoft 
Power BI for business 
intelligence. 
Simulation and 
Modeling 
Allows AI agents to create 
and manipulate models of 
real-world scenarios for 
training, assessment, and 
simulations. They foster 
experiential learning 
opportunities. 
AnyLogic: simulation 
modeling, MATLAB: 
mathematical 
modeling 
Interaction and 
Communication 
Tools 
Interaction and 
Communication 
Facilitates interactions 
between AI agents and users 
or between multiple agents, 
enhancing collaboration and 
feedback mechanisms. 
Chatbot frameworks 
such as Rasa for 
conversational 
interfaces, Zoom API: 
virtual meetings. 
Governance 
and Evaluation 
Tools 
Monitoring and
```

</details>

---

### 14. Evaluation

**Score: 8.0/10**

**Evaluation:**
The section demonstrates strong technical depth and coherence, effectively exploring tool-use systems in educational AI contexts. Its strengths include: Clarity and Writing Quality (2/2): - Well-structured prose - Clear explanations of AI tool categories - Logical flow between subsections Technical Depth (2/2): - Comprehensive overview of AI tool ecosystems - Detailed exploration of tool functionalities - Provides concrete examples like Google Analytics, GitHub, Docker Novelty and Originality (1/2): - Presents systematic categorization of AI tools - Some innovative insights into AI-education integration - Slightly limited by somewhat standard tool descriptions Methodology Rigor (1/2): - Includes multiple academic citations - Provides contextual framework for tool use - Could benefit from more explicit methodological explanation Evidence and Support (2/2): - Strong academic citations - Empirical references from educational technology research - Balanced discussion of tool capabilities and challenges

**Summary:**
The section comprehensively examines AI tool-use systems in education, categorizing tools across evaluation, ethics, development, and deployment domains. It highlights how AI agents can enhance learning experiences through dynamic interactions, personalized support, and collaborative knowledge creation, while also acknowledging potential implementation challenges. The analysis demonstrates a nuanced understanding of AI's transformative potential in educational technology, emphasizing both technological capabilities and human-centric approaches.

<details>
<summary>📄 View Section Content (4092 characters)</summary>

```
Evaluation 
Helps assess performance 
and engagement metrics, 
providing insights into user 
interactions and outcomes. 
Google Analytics for 
tracking user 
engagement, 
formative assessment 
tools for real-time 
feedback. 
Ethics and 
Fairness 
Focuses on ensuring that AI 
systems operate within ethical 
guidelines, promoting fairness 
and accountability in 
decision-making processes. 
Fairness Indicators for 
evaluating model 
fairness, AI ethics 
frameworks for 
compliance with 
ethical standards. 
Development 
and 
Deployment 
Tools 
Development and 
Collaboration 
Supports the collaborative 
development of AI 
applications, allowing teams 
to work together effectively 
while building and deploying 
AI systems. 
GitHub for version 
control and 
collaboration, Jupyter 
Notebooks for 
interactive coding and 
sharing of AI models. 
Deployment and 
Scaling 
Assists in the deployment of 
AI applications and their 
scaling to accommodate 
larger user bases or more 
complex tasks, ensuring 
efficiency in operation. 
Docker for 
containerization, 
Kubernetes for 
orchestration of 
containerized 
applications. 
 
By utilizing a combination of these types of tools, AI agents can effectively process data, interact 
with users, and create meaningful learning experiences. As the integration of AI in education 
continues to evolve, understanding these tool-use systems in the educational settings will be 
critical for optimizing their application and maximizing the benefits for learners and educators 
alike. 
 
4.3.3. Tool - Use systems in Education 
Tool-use systems in education leverage the capabilities of AI agents to enhance learning 
experiences through dynamic interactions with various educational resources. These systems 
facilitate personalized and effective learning environments by coordinating multiple tools tailored 
to specific educational tasks (Chin et al., 2010; Ouyang & Jiao, 2021). For example, AI agents 
can utilize adaptive learning platforms and educational APIs to provide real-time feedback and 
support individualized learning paths, aligning with the AI-supported, learner-as-collaborator 
paradigm (Ouyang & Jiao, 2021). 
One significant advantage of tool-use systems is their ability to actively engage learners. By 
integrating tools for document annotation, quiz generation, and performance analytics, AI 
agents assist educators in tracking student progress and adapting instructional strategies 
accordingly (Baker et al., 2019). This collaborative approach fosters a co-creation of knowledge 
between AI systems and students, thus enhancing the learning process (Holmes et al., 2019; 
Luckin & Cukurova, 2019). Additionally, these systems provide substantial benefits to teachers. 
AI agents can automate administrative tasks such as grading and attendance tracking, allowing 
teachers to focus more on instructional activities and student engagement. By analyzing student 
performance data, AI can also offer insights into class trends and individual student needs, 
enabling teachers to tailor their instruction more effectively. This data-driven approach helps 
educators identify which students may require additional support, ultimately improving learning 
outcomes (Luckin et al., 2016). Moreover, the iterative reasoning capabilities inherent in tool-use 
systems allow AI agents to reflect on previous interactions and adjust their strategies based on 
the evolving needs of learners. This reflective practice is essential in educational contexts, as 
understanding a student's unique learning trajectory can lead to more effective interventions 
(Zawacki-Richter et al., 2019). For instance, utilizing data analytics tools enables AI agents to 
identify patterns in student performance data, recommending personalized resources that cater 
to individual strengths and weaknesses. 
Table 4.6 below highlights the relevant literature of tool-use systems in education. 
4.6 Tool-use systems in Education 
 
4.3.4. Limitations and Challenges 
Despite the advantages, the implementation of tool-use systems in education faces several
```

</details>

---

### 15. Limitations And Challenges. One Significant Issue Is The Seamless Integration Of Various

**Score: 8.0/10**

**Evaluation:**
The section demonstrates strong qualities across the evaluation criteria: Clarity and Writing Quality (2/2): - Well-structured and coherently written - Clear articulation of key challenges in AI educational tool integration - Logical flow of arguments Technical Depth (2/2): - Comprehensive exploration of integration challenges - Addresses multiple dimensions: technical interoperability, data privacy, ethical concerns - Cites relevant contemporary research - Provides nuanced analysis of systemic challenges Novelty and Originality (1/2): - Covers known challenges in AI educational technology - Slightly incremental rather than groundbreaking - Good synthesis of existing research perspectives Methodology Rigor (1/2): - Sound conceptual framework - References multiple scholarly sources - Could benefit from more empirical evidence or specific case studies Evidence and Support (2/2): - Strong citation network - Multiple references from recent years (2016-2025) - Diverse sources covering technical, ethical, and implementation perspectives

**Summary:**
The section critically examines challenges in integrating AI educational tools, focusing on interoperability, data privacy, algorithmic bias, and educator adaptation. It highlights the need for comprehensive implementation frameworks that balance technological potential with ethical considerations, emphasizing collaboration between educators, students, and AI developers to transform learning experiences. The score of 8 reflects a high-quality section with robust analysis and comprehensive coverage, requiring minor refinements to achieve exceptional status.

<details>
<summary>📄 View Section Content (2955 characters)</summary>

```
limitations and challenges. One significant issue is the seamless integration of various 
educational tools and platforms. The literature emphasizes the necessity for robust 
interoperability standards to ensure smooth data flow between systems (Pinkwart, 2016). 
Without these standards, the effectiveness of tool-use systems can be significantly hampered, 
leading to fragmented learning experiences. More importantly, concerns about data privacy and 
Author(s) 
Summary 
Relevant Tool-Use 
type 
Sellar & Gulson 
(2020) 
Analyzed AI's impact on education policy and 
governance. The tool used brought in policy 
implications of AI in education. 
Ethics and Fairness tools 
Winters et al. 
(2020) 
Explored digital structural violence in education 
and strategies to combat it. The tool assisted in 
implementation of strategies addressing 
inequities in educational technology. 
Ethics and Fairness tools 
Ouyang & Jiao 
(2021) 
Identified three paradigms of AI in education: 
AI-directed (Intelligent Tutoring Systems), 
AI-supported (Dialogue-based Tutoring 
Systems), and AI-empowered. 
Communication and 
Interaction tools 
Barua (2024) 
Explored LLMs' potential in creating 
autonomous agents with various capabilities 
across domains. LLMs used for tasks like 
customer service, healthcare diagnostics, and 
email responses 
Simulation and Modeling 
tools 
the ethical implications of automated decision-making (Hultberg et al., 2024; Kamalov et al., 
2023) in educational settings are critical challenges. As AI systems collect and analyze vast 
amounts of student data via multiple tools , ensuring the security and privacy of this information 
becomes paramount (Kamalov et al., 2023). The potential for bias in AI algorithms and tools 
also raises ethical questions about fairness and equity in educational outcomes (Ouyang & Jiao, 
2021). Another challenge is the need for educators to adapt to these new tools and technologies 
by upskilling and reskilling (Santandreu Calonge et al., 2025). Many educators may lack the 
necessary training and support to effectively implement and integrate AI-driven tools into their 
teaching practices (Zawacki-Richter et al., 2019). This gap can lead to resistance to adopting AI 
tools, limiting their potential benefits in the classroom. 
 
To tackle these challenges, educational institutions must develop comprehensive frameworks 
that guide the implementation of AI tool-use systems. This includes establishing clear data 
management guidelines, fostering collaboration between educators, students and AI developers 
(Santandreu Calonge et al., 2025), and ensuring alignment with pedagogical goals (Ouyang & 
Jiao, 2021). By prioritizing these aspects, educational stakeholders can harness the potential of 
tool-use systems to transform, ‘super-personalise’ learning experiences (Popenici, 2023), and 
promote learner agency. In conclusion, tool-use systems in education represent a transformative
```

</details>

---

### 16. Approach, Enabling Ai Agents To Enhance Engagement, Support Personalized Learning, And

**Score: 8.0/10**

**Evaluation:**
1. Clarity and Writing Quality (2/2): The section is well-written, coherent, and presents complex technical concepts in a clear, accessible manner. The language is precise and academic, with smooth transitions between ideas. 2. Technical Depth (2/2): Demonstrates exceptional technical depth by exploring multi-agent AI systems. The analysis goes beyond surface-level descriptions, delving into architectural nuances, advantages, and limitations of different agent configurations. 3. Novelty and Originality (1.5/2): Offers novel insights into multi-agent systems, particularly in educational contexts. The discussion of how multiple AI agents can collaborate, decompose tasks, and mitigate individual agent limitations is innovative. 4. Methodology Rigor (1.5/2): Provides a structured approach to analyzing multi-agent systems, supported by recent research citations. The breakdown of architectures and advantages is methodically presented, though could benefit from more explicit methodological details. 5. Evidence and Support (1/2): Strong citation base with recent sources (Xie et al., 2023; Wang et al., 2023b), but could use more empirical evidence demonstrating the practical outcomes of multi-agent systems.

**Summary:**
The section explores multi-agent AI systems as a promising approach to enhancing educational technology, highlighting their ability to improve problem-solving, manage complexity, and provide specialized expertise. By examining different architectural models and collaborative mechanisms, the text demonstrates how multiple AI agents can work together to create more robust and adaptable learning environments.

<details>
<summary>📄 View Section Content (4449 characters)</summary>

```
approach, enabling AI agents to enhance engagement, support personalized learning, and 
facilitate collaborative practices. As these systems continue to evolve, their effective 
implementation will be critical in shaping the future of education, making it more responsive to 
the diverse needs of learners (Ouyang & Jiao, 2021). 
 
3.4 Multi Agent Systems 
Recent advancements in natural language processing (NLP) have led to the emergence of 
highly capable agents that draw on LLMs for complex reasoning, tool usage, and real-time 
adaptation to novel observations (Xie et al., 2023; Wang et al., 2023b). As the variety and 
complexity of tasks suited to LLMs continue to grow, an effective approach to amplifying agent 
performance is to employ multiple agents working in tandem. Beyond improving efficiency, such 
collaboration also offers pathways to developing more sustainable AI-driven systems. Previous 
research shows that multi-agent approaches can foster divergent thinking (Liang et al., 2023), 
enhance factual accuracy and reasoning (Du et al., 2024), and provide systematic validation 
(Wu et al., 2024). By orchestrating multiple AI agents, educational platforms can leverage 
collective intelligence to tackle interdisciplinary challenges—including those related to 
sustainability—while optimizing resources and reinforcing long-term viability. 
A key motivation for using multi-agent systems is the capacity of chat-optimized LLMs to 
comprehend and respond to feedback. When multiple LLM-based agents communicate—either 
with one another or with human collaborators—they can exchange reasoning steps, 
observations, critiques, and validation through dialogue. In addition, LLMs have demonstrated 
the ability to decompose complex tasks into smaller, more manageable subtasks. Multi-agent 
dialogues can facilitate task partitioning and subsequent reintegration in an intuitive manner that 
allows a more efficient and organized problem-solving process. 
In contrast, single-agent systems face several limitations. First, when a single agent is equipped 
with multiple tools, it may struggle to make optimal decisions about which tool to use for a 
specific task. Second, as task complexity escalates, an overwhelming amount of contextual 
information can exceed the capacity of a single agent to manage effectively. Third, many 
real-world scenarios require multiple areas of specialization, which a single agent may not fully 
encompass. By dividing tasks among specialized agents with diverse expertise, a multi-agent 
paradigm can mitigate these issues and maintain more manageable contexts. As a result, 
multi-agent systems offer a promising avenue for dealing with the increasingly complex and 
specialized tasks in real-world applications. 
Multi-agent approach presents several practical advantages, including modularity, 
specialization, and control. While the multi-agent approach is similar to the “planning” paradigm, 
it provides greater control over individual components of the system. Increased control and 
modularity allow to reduce the amount of hallucinations which is a major challenge in 
LLM-based applications. A summary of the advantages of the multi-agent approach is 
presented in Table 4.7.   
Table 4.7 Advantages of multi-agent systems. 
Benefit 
Description 
Modularity 
Using separate agents simplifies the development and maintenance of 
agentic systems by allowing isolated updates or replacements without 
disrupting the entire system. 
Specialization 
Dedicated, expert agents can be assigned to specific domains, boosting 
overall performance through focused expertise. 
Control 
Clear and explicit mechanisms for agent interactions (e.g., conversations) 
enable better oversight rather than relying solely on function calls. 
 
4.4.1 Multi Agent Architectures 
There exist several architectures for implementing the multi-agent approach. In the “supervisor” 
architecture, a lead LLM delegates tasks to the subagents in the system. In the “network” 
architecture, each agent can communicate with another agent in the system. Table 4.7 below 
outlines several common multi-agent designs, along with their defining characteristics and 
potential challenges. 
Table 4.7. Multi-agent architectures 
Architecture Key Characteristics 
Potential Challenges 
Single 
(Baseline) 
- Utilizes a single LLM that can call 
multiple tools. - Represents the simplest 
setup. 
- Subject to previously noted
```

</details>

---

### 17. Limitations Such As

**Score: 9.0/10**

**Evaluation:**
The section excels across all evaluated criteria: 1. Clarity and Writing Quality (2/2): - Exceptionally clear and structured prose - Systematically presents limitations of multi-agent systems - Uses well-organized tables and figures to enhance comprehension 2. Technical Depth (2/2): - Provides nuanced, technically sophisticated analysis of multi-agent system architectures - Explores different models (Network, Supervisor, Hierarchical, Custom) - Critically examines technical limitations of each approach 3. Novelty and Originality (2/2): - Introduces an innovative multi-agent essay scoring system (MASS) as a proof-of-concept - Demonstrates practical application of theoretical limitations - Offers novel insights into AI agent collaboration 4. Methodology Rigor (2/2): - Employs rigorous benchmarking against multiple LLMs - Uses statistical tests to validate findings - Transparent methodology with publicly available code 5. Evidence and Support (1/2): - Strong citation of multiple research sources - Empirical evaluation with quantitative results - Slight deduction for potential need for more extensive experimental validation

**Summary:**
The section comprehensively explores multi-agent system limitations in educational technology, presenting a detailed taxonomy of architectural approaches. It culminates in an innovative proof-of-concept multi-agent essay scoring system (MASS), demonstrating how complex AI systems can potentially overcome individual agent constraints while highlighting critical challenges in implementation. The section stands out for its balanced, technically sophisticated analysis of multi-agent AI systems in educational contexts, offering both theoretical insights and practical implementation strategies.

<details>
<summary>📄 View Section Content (12828 characters)</summary>

```
limitations such as 
overwhelmed context and 
insufficient specialization. 
Network 
- Composed of numerous agents, each 
with its own tools and the ability to call 
upon other agents. - Often employed by 
projects such as Swarm or Crew AI. - 
Lacks a designated “leader,” allowing any 
agent to invoke any other agent at any 
time. 
- Less predictable behavior. - 
Potentially expensive due to 
numerous LLM calls. - 
Time-consuming and complex 
to manage in production. 
Supervisor 
- Utilizes a single “supervisor” agent that 
decides which sub-agent to call next. - 
Sub-agents focus on specific domains, 
enhancing specialization. - A simplified 
variant treats sub-agents as tools used by 
the main agent, where the main agent’s 
tool calls handle inter-agent 
communication. 
- Over-reliance on the 
supervisor agent for optimal 
orchestration. - Potential 
bottleneck if the supervisor 
agent is overwhelmed. 
Hierarchical 
- Builds on the supervisor model by 
introducing multiple layers of supervisor 
agents. - Allows for large, domain-specific 
systems to be organized in tiers. 
- Complexity increases with 
each additional supervisory 
layer. - May require extensive 
coordination across tiers. 
Custom 
- Tailored specifically to the requirements 
of a given domain. - Often combines 
elements from supervisor or hierarchical 
models with custom domain logic. 
- Development can be 
resource-intensive due to 
bespoke design. - Requires 
ongoing maintenance for 
evolving domain needs. 
   
3.4.4 Multi Agent Systems in Education 
Multi-agent systems have been increasingly employed in various educational contexts. They are 
particularly beneficial in complex tasks that demand the coordination of multiple components. In 
adaptive learning environments, for instance, individual agents can address distinct facets of the 
learning process—such as identifying knowledge gaps, adjusting content difficulty, or providing 
personalized feedback—thereby accommodating diverse learning styles and paces. 
The use of multi-agent systems in education predates the advent of LLMs (Apoki et al., 2022). 
Viswanathan et al. (2022) propose a multi-agent system consisting of several specialized 
agents: Jade Gateway Agent, Control Agent, Learning Style Detector Agent, Adaptive Course 
Organizer Agent, and User Interface Agent. Similarly, Ivanova et al. (2023) present a design 
based on Learner Agent, Content Agent, and Pedagogical Agent to construct a personalized 
e-learning system. Similarly, Axac et al. (2023) propose a multi-agent system that integrates 
computer vision to construct an online learning platform. One promising avenue for further 
development involves integrating LLMs into the existing multi-agent frameworks. 
Educational simulations represent another active area of multi-agent design application. 
Developing simulations can be both resource-intensive and time-consuming; however, 
advancements in generative AI provide potential solutions to these challenges. Mollick et al. 
(2024) propose “PitchQuest,” a multi-agent AI system for educational simulations. The system 
offers personalized learning experiences by allowing students to practice skills in scenarios 
populated by AI-generated stakeholders. The proposed prototype features multiple agents, 
including Mentor Agent, Investor Agent, Evaluator Agent, Progress Agent, and Class Insights 
Agent. In medical education, Wei et al. (2024) propose “MEDCO,” a multi-agent system that 
simulates realistic training environments by incorporating roles such as patient, doctor, and 
radiologist. Their design promotes interactive, multidisciplinary learning and enhances students’ 
question-asking and collaboration skills in a virtual setting (Williams & Li, 2023). SimClass is a 
multi-agent classroom simulation framework that mimics traditional classroom interactions by 
integrating real user participation and enabling collaborative, role-based teaching dynamics 
(Zhang et al., 2024b). Recent research suggests that multi-agent systems can offer more 
personalized and effective learning experiences by adapting to individual student needs (Chen 
& Zhao, 2023). 
General AI-based methods for automated grading have also attracted scholarly attention 
(Wongvorachan et al., 2022; Yang et al., 2025). While multi-agent systems for automated 
grading have been explored to a limited extent, Guo et al. (2024) describe a system with two AI 
agents: one generates feedback, and the other validates and refines it. This approach 
significantly reduces instances of over-praise and over-inference, thereby yielding more 
accurate and pedagogically sound feedback. Yesilyurt (2023) similarly investigates the potential 
of multi-agent assessment and feedback mechanisms within language learning contexts, further 
underscoring the promise of multi-agent systems in enhancing educational processes. 
 
 
 
Table 4.8. Multi-agent Approaches in Education 
Source 
Domain 
Summary 
Mollick et 
al. (2024) 
Simulation 
Propose PitchQuest, a venture capital pitching simulator. 
Enables personalized learning through AI-generated 
stakeholders and includes multiple agents (Mentor, Investor, 
Evaluator, Progress, Class Insights). 
Wei et al. 
(2024) 
Simulation 
Introduce MEDCO, a multi-agent system that simulates 
real-world training environments by incorporating patient, 
doctor, and radiologist roles, fostering interactive, 
multidisciplinary learning in a virtual setting. 
Zhang et al. 
(2024b) 
Simulation 
Propose SimClass, a multi-agent classroom simulation 
framework that mimics traditional classroom interactions by 
integrating real user participation and enabling collaborative, 
role-based teaching dynamics. 
Jin et al. 
(2024) 
Simulation 
Propose TeachTune, a simulated student agent system to test 
and tune the performance of  pedagogical conversational 
agents 
Ma et al. 
(2024) 
Simulation 
Propose AI4Education framework for modeling virtual student 
agents used for teacher training. 
Guo et al. 
(2024) 
Automated 
Grading 
Develop a multi-agent system featuring two AI agents—one 
generating feedback and the other validating/refining it—for 
automatically scoring student responses with the aim of 
reducing over-praise and over-inference errors. 
Yesilyurt 
(2023) 
Automated 
Grading 
Explore multi-agent assessment and feedback mechanisms in 
language learning contexts, emphasizing how multi-agent 
systems can support more nuanced and effective student 
feedback. 
  
4.4.4 Limitations 
Despite their distinct advantages, multi-agent systems also present several challenges. 
Compared to single-agent approaches, coordinating multiple agents typically increases token 
usage and processing time. The increased resource consumption amplifies computational costs 
and environmental impact. Therefore, an important research goal is minimizing the number of 
interactions required while maintaining agent performance. Another key issue is effectively 
chaining and orchestrating individual agents in the system, as improper coordination can 
diminish the overall system’s performance. Finally, given the propensity for LLMs to hallucinate, 
relying on communicative agents to handle tasks may lead to incomplete or inaccurate outputs 
(Agnihotri & Chug, 2020). Addressing these issues will be crucial for the broader adoption and 
sustainability of multi-agent solutions. 
Multi agent systems can be complex to develop and require careful coordination to ensure 
agents remain aligned with the intended instructional goals. Without proper design, an 
agent-based system may suffer from inconsistencies. A breakdown in communication among 
agents can lead to learner confusion or reduced engagement. Biases in agent decision-making 
can skew interactions, and complex simulations may burden the system. Since agent-based 
interactions vary, students may receive significantly different experiences, which can undermine 
the fairness and consistency of instruction. 
5 Illustrative Application: Multi-agent scoring system 
To provide a concrete example of how agentic paradigms, specifically multi-agent collaboration, 
can be applied in an educational context, we developed a proof-of-concept Multi-Agent Scoring 
System (MASS) for automated essay grading. Essay writing is a fundamental skill, yet manual 
grading is time-consuming and potentially subjective. Automated Grading Systems (AGS) aim to 
address these issues, but single-LLM approaches can suffer from inconsistency and biases like 
over-praise (Guo et al., 2024). 
As a proof of concept for the use of AI agents in education, we propose an automatic essay 
grading system based on a multi-agent approach. The proposed system consists of two 
independent subagents that are supervised by the lead agent (Fig 5.1). The first subagent 
scores an essay based on the content. It checks how well the essay is organized, clear 
coherence and progression of ideas using appropriate examples, reasons, and other evidence 
to support its position. The second agent checks if the essay is free of errors in grammar, 
usage, typos, and mechanics. The lead agent combines the feedback from each subagent to 
produce the final score. By focusing each subagent on a specific facet of essay writing, we aim 
to obtain more accurate feedback. Furthermore, to increase grading consistency, the lead agent 
is conditioned to request multiple reports from the subagents in case of widely divergent 
feedback. 
 
Fig. 5.1 The proposed multi-agent assessment system (MASS) for automated essay grading. 
The proposed multi-agent scoring system (MASS) is based on GPT-4o. We benchmark the 
MASS against several stand-alone LLMs: GPT-4o, DeepSeek 67b, and DeepSeek 1.3b. We use 
the ASAP 2.0 Dataset for our evaluation (Crossley et al., 2024). The dataset comprises about 
17000 student-written argumentative essays. Each essay was scored on a scale of 1 to 6 based 
on a holistic rubric. The code and the technical details of the evaluation are available on GitHub 
(https://github.com/AzizovDilshod/Multi-agent-System-for-Essay-Assessment/tree/main). 
Table 5.1 Comparison of MASS vs single LLMs in automatic essay grading. 
Model 
MAE 
Std Dev of Error 
DeepSeek 1.3B 
1.696 
1.767 
DeepSeek 67B 
0.735 
1.010 
GPT-4o 
0.613 
0.956 
Llama 3.3 70B 
0.614 
0.783 
MASS 
0.561 
0.830 
The results of the evaluation are summarized in Table 5.1. The results show the advantages of 
the proposed MASS based on GPT-4o over stand-alone LLMs for automated essay grading. 
The MASS achieves the lowest mean absolute error (MAE) of 0.5612, indicating that its 
predictions align more closely with the ground truth scores than those of single LLMs. In 
contrast, the stand-alone GPT-4o model has a higher MAE of 0.6129, while the DeepSeek 
models perform worse, with DeepSeek 67b at 0.7345 and DeepSeek 1.3b at 1.6956. Moreover, 
the statistical tests show that the p-values for both the paired t-test and Wilcoxon signed-rank 
test are 0.0 across all comparisons. It indicates that the differences in MAE between MASS and 
each of the single-LLM models are highly statistically significant. 
One of the key advantages of MASS is its lower standard deviation of 0.8295, suggesting that it 
produces more consistent scores across different essays. In comparison, the stand-alone 
GPT-4o model has a higher standard deviation (0.9555), and DeepSeek 67b and 1.3b exhibit 
even greater variability (1.0102 and 1.7666, respectively). The high variability in DeepSeek 
1.3b’s predictions reinforces concerns about grading inconsistency, which is a known limitation 
of AGS based on a single LLM. 
Looking ahead, the implementation of agentic AI also presents opportunities to advance 
sustainability in educational contexts. By reducing computational redundancy through targeted 
task decomposition and collaborative agent frameworks, these systems can minimize energy 
use and resource consumption. Moreover, strategically designed reflection and planning 
processes can optimize the allocation of computing resources, directly addressing the rising 
environmental costs associated with large-scale AI. The holistic approach encourages the 
development of educational platforms that not only excel in adaptability and performance but 
also uphold principles of ecological responsibility and long-term viability 
The superior performance of MASS can be attributed to its multi-agent architecture, where 
separate subagents focus on different aspects of essay quality—content and language 
mechanics—before the lead agent synthesizes their outputs. The structured approach reduces 
errors stemming from over-praise and over-inference, which are common pitfalls in single-LLM 
grading. Additionally, the verification mechanism introduced in MASS can lead to more refined 
and balanced scoring.
```

</details>

---

### 18. Conclusion

**Score: 9.0/10**

**Evaluation:**
The Conclusion section is exceptionally strong, demonstrating remarkable depth, balance, and forward-looking perspective. It excels across all evaluation criteria: 1. Clarity and Writing Quality (2/2): The text is lucid, well-structured, and eloquently articulates complex ideas with precision. Transitions between paragraphs are smooth and logical. 2. Technical Depth (2/2): The section comprehensively synthesizes previous sections' findings, highlighting key design paradigms (reflection, planning, tool use, multi-agent collaboration) and their educational implications with technical sophistication. 3. Novelty and Originality (2/2): The conclusion goes beyond mere summary, introducing innovative perspectives like sustainability in AI and addressing potential environmental impacts of computational approaches. 4. Methodology Rigor (1.5/2): The section critically acknowledges both achievements and unresolved challenges, demonstrating methodological maturity. The future research subsection provides a nuanced, strategic roadmap for continued investigation. 5. Evidence and Support (1.5/2): Claims are well-grounded in previous research, with clear connections to earlier sections and a balanced presentation of potential benefits and limitations. The section's standout feature is its holistic approach, addressing technological potential while simultaneously emphasizing ethical considerations, educational equity, and long-term societal implications.

**Summary:**
The Conclusion synthesizes the paper's exploration of AI agents in education, highlighting their potential to enhance learning through adaptive, collaborative workflows. It critically examines the transformative promise of AI technologies while acknowledging significant challenges in implementation, suggesting a comprehensive research agenda focused on transparency, equity, and meaningful human-AI interaction in educational contexts.

<details>
<summary>📄 View Section Content (4392 characters)</summary>

```
6 Conclusion 
In this paper, we explored how emerging AI agents can address the limitations of conventional 
LLMs in education. Our analysis was based on four key design paradigms—reflection, planning, 
tool use, and multi-agent collaboration. The survey of existing literature revealed the potential 
for the agentic workflows to offer greater adaptability, enhanced reasoning, and more consistent 
performance in educational settings. Furthermore, the proposed proof-of-concept multi-agent 
essay scoring system demonstrated the advantages of agentic workflows over stand-alone 
LLMs. 
 
By incorporating real-time data, iterative feedback loops, and strategic task decomposition, AI 
agents overcome the static nature of traditional LLMs, making them powerful reasoning 
‘partners’ or assistive tools. The new paradigm enables the delivery of more robust and 
trustworthy AI-driven solutions for educational needs in a variety of tasks. In particular, the 
multi-agent essay-scoring framework highlights how collaborative systems can improve 
reliability, consistency, and scalability of AI systems in education. 
 
Looking ahead, the implementation of agentic AI also presents opportunities to advance 
sustainability in educational contexts. By reducing computational redundancy through targeted 
task decomposition and collaborative agent frameworks, these systems can minimize energy 
use and resource consumption. Moreover, strategically designed reflection and planning 
processes can optimize the allocation of computing resources, directly addressing the rising 
environmental costs associated with large-scale AI. This holistic approach encourages the 
development of educational platforms that not only excel in adaptability and performance but 
also uphold principles of ecological responsibility and long-term viability. 
 
Despite our findings, integrating agentic workflows into diverse educational contexts holds 
several unresolved challenges. Achieving transparency in decision-making processes, ensuring 
fairness and accountability, and establishing ethical guidelines remain notable concerns. 
Designing systems that reliably transfer across heterogeneous learner populations and different 
pedagogical settings also warrants further investigation. Finally, the interplay between human 
instructors, learners, and AI agents must be systematically studied to ensure that agentic 
solutions support rather than supplant meaningful educational interactions. 
6.1 Future Research 
There are several avenues for future research to address the remaining challenges in 
deployment of AI agents in education. These include refining AI architectures to improve 
interpretability, exploring various strategies that better align with specific pedagogical goals, and 
developing policy frameworks to ensure fair and equitable deployment of AI agents in classroom 
settings. To address skepticism and resistance from stakeholders, including teachers, parents, 
and policymakers, research should focus on making AI agent reasoning transparent to 
educators and students (Explainable AI (XAI)).  
Educational environments are dynamic and new technologies are constantly being introduced. 
Future research could focus on developing AI agents that are adaptive, context-aware, and can 
adapt to changing student needs, languages, culture, learning preferences, context (s) 
(disadvantaged, refugee, remote, etc.) to avoid exacerbating the digital divide. It is also 
important to study the effectiveness of low-cost or open-source AI solutions in under-resourced 
schools and communities. Additionally,  more longitudinal research is needed to understand the 
long-term effects of AI on student learning outcomes, skills, teacher practices, and the overall 
educational ecosystem. It is crucial to investigate whether prolonged exposure to AI agents 
affects students’ ability to be creative, engage in self-directed learning or collaborate with peers. 
Finally, closer cooperation between AI developers and educators is required to achieve better 
systems that take into account the needs of the students and instructors.  
With breakthroughs happening daily and innovation pushing the boundaries of what is possible, 
intelligent, agentic workflows offer a transformative promise: to reshape the very fabric of 
education and unlock/ augment human potential on an unprecedented scale.
```

</details>

---

### 19. References

**Score: 9.0/10**

**Evaluation:**
The References section demonstrates exceptional quality across the evaluation criteria: 1. Clarity and Writing Quality (2/2): - References are meticulously formatted - Covers diverse sources spanning multiple years (2017-2024) - Includes academic journals, conferences, preprints, and web resources 2. Technical Depth (2/2): - Comprehensive range of sources covering multi-agent AI systems - Strong representation of educational technology and AI research - Includes cutting-edge publications from 2024 - Represents interdisciplinary perspectives (education, computer science, AI) 3. Novelty and Originality (2/2): - Includes recent arXiv preprints exploring innovative AI agent concepts - References emerging research on AI in education - Highlights contemporary discussions on AI agent design and implementation 4. Methodology Rigor (1/2): - Multiple sources discussing methodological approaches - Some references directly address research methodologies - Slight deduction for potential methodological variation 5. Evidence and Support (2/2): - Robust citation network supporting research claims - Diverse sources from reputable institutions and conferences - Strong supporting evidence for paper's core arguments

**Summary:**
The References section provides a comprehensive, technically sophisticated compilation of sources exploring AI agents in educational contexts. It demonstrates deep engagement with contemporary research, covering theoretical foundations, practical implementations, and emerging technological trends in multi-agent AI systems for education.

<details>
<summary>📄 View Section Content (8122 characters)</summary>

```
References 
1.​ Abuelsaad, T., Akkil, D., Dey, P., Jagmohan, A., Vempaty, A., & Kokku, R. (2024). 
Agent-e: From autonomous web navigation to foundational design principles in agentic 
systems. arXiv preprint arXiv:2407.13032. 
2.​ Aderibigbe, A. O., Ohenhen, P. E., Nwaobia, N. K., Gidiagba, J. O., & Ani, E. C. (2023). 
Artificial intelligence in developing countries: bridging the gap between potential and 
implementation. Computer Science & IT Research Journal, 4(3), 185-199. 
3.​ Agnihotri, M., & Chug, A. (2020). A systematic literature survey of software metrics, code 
smells and refactoring techniques. Journal of Information Processing Systems, 16(4), 
915–934. 
4.​ Apoki, U. C., Hussein, A. M. A., Al-Chalabi, H. K. M., Badica, C., & Mocanu, M. L. 
(2022). The role of pedagogical agents in personalised adaptive learning: A review. 
Sustainability, 14(11), 6442. 
5.​ Axak, N., Kushnaryov, M., & Tatarnykov, A. (2023, September). The Agent-Based 
Learning Platform. In ICST (pp. 263-275). 
6.​ Baker, T., Smith, L., & Anissa, N. (2019). Educ-AI-tion rebooted? Exploring the future of 
artificial intelligence in schools and colleges. Retrieved from 
https://www.nesta.org.uk/report/education-rebooted/ 
7.​ Barua, S. (2024). Exploring autonomous agents through the lens of large language 
models: A review. arXiv preprint arXiv:2404.04442. 
8.​ Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of 
stochastic parrots: Can language models be too big? Proceedings of the 2021 ACM 
Conference on Fairness, Accountability, and Transparency, 610–623.  
9.​ Chan, C. K. Y. (2023). A comprehensive AI policy education framework for university 
teaching and learning. International journal of educational technology in higher 
education, 20(1), 38. 
10.​Chase, H. (2024, June). What is an agent? https://blog.langchain.dev/what-is-an-agent/. 
Blog post. 
11.​Chen, F., & Zhao, L. (2023). Dynamic learning experiences in multi-agent systems for 
education. Hu, S., Lu, C., & Clune, J. (2024). Automated design of agentic systems. 
arXiv preprint arXiv:2408.08435.arXiv preprint arXiv:2311.03289. 
12.​Chin, D. B., Dohmen, I. M., Cheng, B. H., Oppezzo, M. A., Chase, C. C., & Schwartz, D. 
L. (2010). Preparing students for future learning with teachable agents. Educational 
Technology Research and Development, 58(6), 649–669. 
13.​Copyleaks. (2024). Bridging the Gap: AI Adoption and Perspectives in Education, 2024. 
https://copyleaks.com/blog/bridging-the-gap-ai-adoption-and-perspectives-in-education-2
024 
14.​Crossley, S., Baffour, P., King, J., Burleigh, L., Reade, W., & Demkin, M. (2024). Learning 
Agency Lab - Automated Essay Scoring 2.0. Kaggle. 
[https://kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2](https:/
/kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2) 
15.​CrewAI. (n.d.). CrewAI Website. https://www.crewai.com/  
16.​Cukurova, M. (2024). The Interplay of Learning, Analytics, and Artificial Intelligence in 
Education. arXiv preprint arXiv:2403.16081. 
17.​Cukurova, M., Kent, C., & Luckin, R. (2019). Artificial intelligence and multimodal data in 
the service of human decision-making: A case study in debate tutoring. British Journal of 
Educational Technology, 50(6), 3032–3046. 
18.​Dai, C. P., Ke, F., Pan, Y., Moon, J., & Liu, Z. (2024). Effects of artificial 
intelligence-powered virtual agents on learning outcomes in computer-based 
simulations: A meta-analysis. Educational Psychology Review, 36(1), 31. 
19.​DeepLearning.ai. (2024). Agentic Design Patterns: Reflection. Retrieved from 
https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/  
20.​DeepSeek. (2024). DeepSeek official website.Retrieved January 2025, from 
https://www.deepseek.com 
21.​Du, H., Jia, Q., Gehringer, E., & Wang, X. (2024). Harnessing large language models to 
auto-evaluate the student project reports. Computers and Education: Artificial 
Intelligence, 7, 100268. 
22.​Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., & Mordatch, I. (n.d.). Improving Factuality 
and Reasoning in Language Models through Multiagent Debate. In Forty-first 
International Conference on Machine Learning. 
23.​Dwivedi, Y. K., Hughes, L., Ismagilova, E., Aarts, G., Coombs, C., Crick, T., ... & 
Williams, M. D. (2021). Artificial Intelligence (AI): Multidisciplinary perspectives on 
emerging challenges, opportunities, and agenda for research, practice and policy. 
International journal of information management, 57, 101994. 
24.​Gou, Z., et al. (2024). CRITIC: Large Language Models Can Self-Correct with 
Tool-Interactive Critiquing. ICLR 2024. Retrieved from https://arxiv.org/abs/2305.11738  
25.​Guo, S., Latif, E., Zhou, Y., Huang, X., & Zhai, X. (2024). Using Generative AI and 
Multi-Agents to Provide Automatic Feedback. arXiv preprint arXiv:2411.07407. 
26.​Gulson, K. N., & Witzenberger, K. (2020). Repackaging authority: Artificial intelligence, 
automated governance and education trade shows. Journal of Education Policy, 1–16. 
27.​Gur, I., Furuta, H., Huang, A., Safdari, M., Matsuo, Y., Eck, D., & Faust, A. (2023). A 
real-world webagent with planning, long context understanding, and program synthesis. 
arXiv preprint arXiv:2307.12856. 
28.​Habbal, A., Ali, M. K., & Abuzaraida, M. A. (2024). Artificial Intelligence Trust, risk and 
security management (AI trism): Frameworks, applications, challenges and future 
research directions. Expert Systems with Applications, 240, 122442. 
29.​Hao, H., Wang, Y., & Chen, J. (2024). Empowering Scenario Planning with Artificial 
Intelligence: A Perspective on Building Smart and Resilient Cities. Engineering. 
30.​Holmes, W., Bialik, M., & Fadel, C. (2019). Artificial intelligence in education: Promises 
and implications for teaching and learning. Center for Curriculum Redesign. 
31.​Hong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., Zhang, C., et al. (n.d.). 
MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. In The Twelfth 
International Conference on Learning Representations. 
32.​Hu, S., & Clune, J. (2024). Thought cloning: Learning to think while acting by imitating 
human thinking. Advances in Neural Information Processing Systems, 36. 
33.​Hu, S., Lu, C., & Clune, J. (2024). Automated design of agentic systems. arXiv preprint 
arXiv:2408.08435. 
34.​Huang, P. S., et al. (2023). Reflexion: Language Agents with Verbal Reinforcement 
Learning Feedback. arXiv preprint arXiv:2303.17651. 
35.​Hultberg, P. T., Santandreu Calonge, D., Kamalov, F., & Smail, L. (2024). Comparing and 
assessing four AI chatbots’ competence in economics. Plos one, 19(5), e0297804. 
36.​Hultberg, P., Calonge, D. S., & Lee, A. E. S. (2018). Promoting long-lasting learning 
through instructional design. Journal of the Scholarship of Teaching and Learning, 18(3). 
37.​Hultberg, P. T., & Calonge, D. S. (2017). Effective teaching of economics: A constrained 
optimization problem?. The Journal of Economic Education, 48(4), 265-275. 
38.​Ivanova, T., Terzieva, V., & Todorova, K. (2021, October). An Agent-Oriented 
Architecture for Strategy-Based Personalized E-Learning. In 2021 Big Data, Knowledge 
and Control Systems Engineering (BdKCSE) (pp. 1–8). IEEE. 
39.​Jin, H., Yoo, M., Park, J., Lee, Y., Wang, X., & Kim, J. (2024). TeachTune: Reviewing 
Pedagogical Agents Against Diverse Student Profiles with Simulated Students. arXiv 
preprint arXiv:2410.04078. 
40.​Kabudi, T., Pappas, I., & Olsen, D. H. (2021). AI-enabled adaptive learning systems: A 
systematic mapping of the literature. Computers and Education: Artificial Intelligence, 2, 
100017. 
41.​Kamalov, F., Santandreu Calonge, D., & Gurrib, I. (2023). New era of artificial 
intelligence in education: Towards a sustainable multifaceted revolution. Sustainability, 
15(16), 12451. 
42.​Kaswan, K. S., Dhatterwal, J. S., & Ojha, R. P. (2024). AI in personalized learning. In 
Advances in Technological Innovations in Higher Education (pp. 103-117). CRC Press. 
43.​Kikalishvili, S. (2024). Unlocking the potential of GPT-3 in education: Opportunities,
```

</details>

---

### 20. Limitations, And Recommendations For Effective Integration. Interactive Learning

**Score: 3.0/10**

**Evaluation:**
This section appears to be a compilation of references rather than a substantive discussion of limitations and recommendations for interactive learning environments. The key issues are: 1. Clarity and Writing Quality (0.5/2): No actual text or discussion is present; it's merely a list of references. 2. Technical Depth (0.5/2): While the references suggest potential depth, there's no actual analytical content explaining limitations or recommendations. 3. Novelty and Originality (0.5/2): No original insights are presented. 4. Methodology Rigor (0.5/2): No methodological discussion is evident. 5. Evidence and Support (1/2): The references are current and from reputable sources, which is the only positive aspect. The section fails to fulfill its implied purpose of discussing limitations and recommendations for interactive learning. It seems like a misplaced references section or an incomplete draft.

**Summary:**
This section lacks substantive content, presenting only a list of academic references without any accompanying analysis, discussion of limitations, or recommendations for interactive learning environments. The references suggest potential research on AI in education, but no actual insights are provided in this section.

<details>
<summary>📄 View Section Content (11227 characters)</summary>

```
limitations, and recommendations for effective integration. Interactive Learning 
Environments, 32(9), 5587-5599. 
44.​Kouam, A.W.F; & Muchowe, R.M. (2025). Assessing the role of AI technology in 
mitigating the equity gap in educational access in Zimbabwe: Barriers and implications. 
Journal of Applied Learning & Teaching, 8(1).  
45.​Kosslyn, S. M. (2017). The Science of Learning: Mechanisms and Principles. MIT Press. 
46.​LangChain. (n.d.). LangGraph Website. https://www.langchain.com/langgraph 
47.​Lee, G. G., Latif, E., Wu, X., Liu, N., & Zhai, X. (2024). Applying large language models 
and chain-of-thought for automatic scoring. Computers and Education: Artificial 
Intelligence, 6, 100213. 
48.​Liang, T., He, Z., Jiao, W., Wang, X., Wang, Y., Wang, R., ... & Tu, Z. (2023). 
Encouraging divergent thinking in large language models through multi-agent debate. 
arXiv preprint arXiv:2305.19118. 
49.​Luckin, R., & Cukurova, M. (2019). Designing educational technologies in the age of AI: 
A learning sciences-driven approach. British Journal of Educational Technology, 50(6), 
2824–2838. 
50.​Luckin, R., Holmes, W., Griffiths, M., & Forcier, L. B. (2016). Intelligence unleashed: An 
argument for AI in education. Pearson Education. 
51.​Ma, Y., Hu, S., Li, X., Wang, Y., Liu, S., & Cheong, K. H. (2024). Students Rather Than 
Experts: A New AI For Education Pipeline To Model More Human-Like And Personalised 
Early Adolescents. arXiv preprint arXiv:2410.15701. 
52.​Madaan, A., et al. (2023). SELF-REFINE: Iterative Refinement with Self-Feedback. 
Preprint. Retrieved from https://arxiv.org/abs/2303.17651  
53.​Masterman, T., Besen, S., Sawtell, M., & Chao, A. (2024). The landscape of emerging ai 
agent architectures for reasoning, planning, and tool calling: A survey. arXiv preprint 
arXiv:2404.11584. 
54.​Mollick, E., Mollick, L., Bach, N., Ciccarelli, L. J., Przystanski, B., & Ravipinto, D. (2024). 
AI agents and education: Simulated practice at scale. arXiv preprint arXiv:2407.12796. 
https://doi.org/10.48550/arXiv.2407.12796  
55.​Ng, A. (2024, March 20). Agentic design patterns part 1: Four AI agent strategies that 
improve GPT-4 and GPT-3.5 performance. DeepLearning.AI. 
https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/ 
56.​Ouyang, F., & Jiao, P. (2021). Artificial Intelligence in Education: The Three Paradigms. 
Computers and Education: Artificial Intelligence, 2, Article ID: 
100020.https://doi.org/10.1016/j.caeai.2021.100020 
57.​Pinkwart, N. (2016). Another 25 years of AIED? Challenges and opportunities for 
intelligent educational technologies of the future. International Journal of Artificial 
Intelligence in Education, 26(2), 771–783. 
58.​Popenici, S. (2023). The critique of AI as a foundation for judicious use in higher 
education. Journal of Applied Learning and Teaching, 6(2). 
59.​phiData. (n.d.). phiData [Website]. Retrieved January 22, 2025, from 
[https://www.phidata.com/](https://www.phidata.com/) 
60.​Qian, C., Liu, W., Liu, H., Chen, N., Dang, Y., Li, J., ... & Sun, M. (2024, August). 
Chatdev: Communicative agents for software development. In Proceedings of the 62nd 
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long 
Papers) (pp. 15174–15186). 
61.​Romero, Alberto. (2024). DeepSeek is Chinese, but its AI models rival OpenAI. The 
Algorithmic Bridge. Retrieved from 
https://www.thealgorithmicbridge.com/p/deepseek-is-chinese-but-its-ai-models?r=2h32q
6&triedRedirect=true  
62.​Rouzegar, H., & Makrehchi, M. (2024). Generative AI for Enhancing Active Learning in 
Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test 
Questions. arXiv preprint arXiv:2406.13903.  
63.​Sajja, R., Sermet, Y., Cikmaz, M., Cwiertny, D., & Demir, I. (2024). Artificial 
intelligence-enabled intelligent assistant for personalized and adaptive learning in higher 
education. Information, 15(10), 596. 
64.​Santandreu Calonge, D., Kamalov, F., Medina Aguerrebere, P., Hassock, L., Smail, L., 
Yousef, D., ... & Abdulla, N. (2025). Upskilling and reskilling in the United Arab Emirates: 
Future-proofing careers with AI skills. Journal of Adult and Continuing Education, 
14779714251315288. 
65.​Sellar, S., & Gulson, K. N. (2019). Becoming information centric: The emergence of new 
cognitive infrastructures in education policy. Journal of Education Policy, 1–18. 
66.​Shah, M., & Calonge, D. S. (2023). Refugees’ experiences with online higher education: 
Impact and implications through the pandemic. Journal of Applied Learning and 
Teaching, 6(1), 209-221. 
67.​Shehata, S., Calonge, D. S., Purnell, P., & Thompson, M. (2023, July). Enhancing 
video-based learning using knowledge tracing: Personalizing students’ learning 
experience with ORBITS. In Proceedings of the 18th workshop on innovative use of NLP 
for Building Educational Applications (BEA 2023) (pp. 100-107). 
68.​Singh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2024, May). Enhancing ai systems 
with agentic workflows patterns in large language model. In 2024 IEEE World AI IoT 
Congress (AIIoT) (pp. 527-532). IEEE. 
69.​Singh, P. (2024, November 24). What is Agentic AI Planning Pattern? 
https://www.analyticsvidhya.com/blog/2024/11/agentic-ai-planning-pattern/ 
70.​Shin, D., Koerber, A., & Lim, J. S. (2024). Impact of misinformation from generative AI on 
user information processing: How people understand misinformation from generative AI. 
New Media & Society, 0(0). https://doi.org/10.1177/14614448241234040 
71.​Shinn, N., et al. (2023). Reflexion: Language Agents with Verbal Reinforcement 
Learning. Preprint. Retrieved from https://arxiv.org/abs/2303.11366  
72.​Turpin, M., Michael, J., Perez, E., & Bowman, S. (2024). Language models don't always 
say what they think: unfaithful explanations in chain-of-thought prompting. Advances in 
Neural Information Processing Systems, 36. 
73.​U.S. Department of Education, Office of Educational Technology. (2023). Artificial 
intelligence and the future of teaching and learning: Insights and recommendations. 
Retrieved from https://www.ed.gov/sites/ed/files/documents/ai-report/ai-report.pdf  
74.​Viswanathan, N., Meacham, S., & Adedoyin, F. F. (2022). Enhancement of online 
education system by using a multi-agent approach. Computers and Education: Artificial 
Intelligence, 3, 100057. 
75.​Wang, X., Chen, Y., Yuan, L., Zhang, Y., Li, Y., Peng, H., & Ji, H. (2024). Executable 
code actions elicit better llm agents. arXiv preprint arXiv:2402.01030. 
76.​Wei, H., Qiu, J., Yu, H., & Yuan, W. (2024). Medco: Medical education copilots based on 
a multi-agent framework [ECCV 2024 Workshop]. arXiv preprint arXiv:2408.12496. 
77.​Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). 
Chain-of-thought prompting elicits reasoning in large language models. Advances in 
neural information processing systems, 35, 24824-24837. 
78.​Williams, E., & Li, C. (2023). Medco: A multi-agent copilot system for medical education. 
arXiv preprint arXiv:2310.20195. 
79.​Winters, N., Eynon, R., Geniets, A., Robson, J., & Kahn, K. (2020). Can we avoid digital 
structural violence in future learning systems? Learning, Media and Technology, 45(1), 
17–30. 
80.​Wongvorachan, T., Lai, K. W., Bulut, O., Tsai, Y.-S., & Chen, G. (2022). Artificial 
intelligence: Transforming the future of feedback in education. Journal of Applied Testing 
Technology, 95–116. 
81.​Xu, S., Zhang, X., & Qin, L. (2024). EduAgent: Generative student agents in learning. 
arXiv. https://doi.org/10.48550/arXiv.2404.07963  
82.​Xu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y., & Xu, D. (2023). Rewoo: Decoupling 
reasoning from observations for efficient augmented language models. arXiv preprint 
arXiv:2305.18323. 
83.​Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., ... & Wang, C. (2024, October). 
Autogen: Enabling next-gen LLM applications via multi-agent conversations. In First 
Conference on Language Modeling. 
84.​Wu, Y., Jia, F., Zhang, S., Li, H., Zhu, E., Wang, Y., ... & Wang, C. (2024). MathChat: 
Converse to Tackle Challenging Math Problems with LLM Agents. In ICLR 2024 
Workshop on Large Language Model (LLM) Agents. 
85.​Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., ... & Gui, T. (2023). The rise and 
potential of large language model based agents: A survey. arXiv preprint 
arXiv:2309.07864. 
86.​Yang, J., Latif, E., He, Y., & Zhai, X. (2025). Fine-tuning ChatGPT for Automatic Scoring 
of Written Scientific Explanations in Chinese. arXiv preprint arXiv:2501.06704. 
87.​Yao, J., Zhang, S., Yao, Y., Wang, F., Ma, J., Zhang, J., et al. (2022). Edge-cloud 
polarization and collaboration: A comprehensive survey for ai. IEEE Transactions on 
Knowledge and Data Engineering, 35(7), 6866-6886. 
88.​Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., & Narasimhan, K. (2024). Tree 
of thoughts: Deliberate problem solving with large language models. Advances in Neural 
Information Processing Systems, 36. 
89.​Yesilyurt, Y. E. (2023). Ai-enabled assessment and feedback mechanisms for language 
learning: Transforming pedagogy and learner experience. In Transforming the language 
teaching experience in the age of ai (pp. 25–43). IGI Global. 
90.​Yusuf, H., Money, A., & Daylamani-Zad, D. (2025). Pedagogical AI conversational 
agents in higher education: a conceptual framework and survey of the state of the art. 
Educational technology research and development, 1-60. 
91.​Zawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review 
of research on artificial intelligence applications in higher education – Where are the 
educators? International Journal of Educational Technology in Higher Education, 16(39). 
92.​Zeng, F., Lyu, Z., Li, Q., & Li, X. (2024). Enhancing LLMs for Impression Generation in 
Radiology Reports through a Multi-Agent System. arXiv preprint arXiv:2412.06828. 
93.​Zhang, Y., Zhang, K., Pang, Y., & Sekimoto, Y. (2024a, December). Agentic Large 
Language Models for Generating Large-Scale Urban Daily Activity Patterns. In 2024 
IEEE International Conference on Big Data (BigData) (pp. 6815-6822). IEEE. 
94.​Zhang, Z., Zhang-Li, D., Yu, J., Gong, L., Zhou, J., Liu, Z., Hou, L., & Li, J. (2024b). 
Simulating classroom education with llm-empowered agents. arXiv preprint 
arXiv:2406.19226. 
95.​Zhong, L., Wang, Z., & Shang, J. (2024). Ldb: A large language model debugger via 
verifying runtime execution step-by-step. arXiv preprint arXiv:2402.16906. 
 
 
 
 
Statements & Declarations 
The authors declare that no funds, grants, or other support were received during the 
preparation of this manuscript. 
The authors have no relevant financial or non-financial interests to disclose. 
All authors contributed to the study conception and design. Material preparation, data 
collection and analysis were performed by [Firuz Kamalov], [David Santandreu 
Calonge], [Linda Smail], [Dilshod Azizov], [Dimple R. Thadani], [Theresa Kwong], and 
[Amara Atif]. The first draft of the manuscript was written by [Firuz Kamalov] and all 
authors commented on previous versions of the manuscript. All authors read and 
approved the final manuscript.
```

</details>

---

## Technical Details

- **PDF Path**: `papers/Bottom-3-2504.20082v1.pdf`
- **Processing Configuration**:
  - max_chunk_size: 4000
  - min_chunk_size: 100
  - delay_between_requests: 1.0

*Analysis generated by Research Paper Scorer v0.1.0*
